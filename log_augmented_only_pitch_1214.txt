disable_cp = False
mask_strategy = ['bar']
convert_encoding = OCTMIDI
crop_length = None
2022-12-14 22:25:59 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'tensorboard_logdir': 'checkpoints/board_apex_M2P_1e-4_small_tmp', 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': 'musicbert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': 4, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 7000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoints/checkpoint_last_musicbert_small.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '_xai_apex_M2P_1e-4_small_tmp.pt', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='musicbert_small', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-4_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[0.0001], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-4_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'task': Namespace(_name='xai', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-4_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[0.0001], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-4_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'criterion': Namespace(_name='M2P_xai', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-4_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[0.0001], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-4_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 300, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 7000.0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}
2022-12-14 22:25:59 | INFO | musicbert | [input] dictionary: 1237 types
2022-12-14 22:25:59 | INFO | musicbert | [label] dictionary: 497 types
2022-12-14 22:25:59 | INFO | fairseq.data.data_utils | loaded 1,545 examples from: processed/xai_data_bin_apex_reg_cls_augmented/0/input0/valid
dataset: 1545
labels: 1545
2022-12-14 22:26:00 | INFO | fairseq_cli.train | MusicBERTModel(
  (encoder): MusicBERTEncoder(
    (sentence_encoder): OctupleEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(1237, 512, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(8194, 512, padding_idx=1)
      (emb_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (downsampling): Sequential(
        (0): Linear(in_features=4096, out_features=512, bias=True)
      )
      (upsampling): Sequential(
        (0): Linear(in_features=512, out_features=4096, bias=True)
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=512, out_features=512, bias=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict(
    (xai_head): RobertaClassificationHead(
      (dense): Linear(in_features=512, out_features=512, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (out_proj): Linear(in_features=512, out_features=13, bias=True)
    )
  )
  (regression_heads): ModuleDict()
)
2022-12-14 22:26:00 | INFO | fairseq_cli.train | task: MusicBERTSentencePredictionMultilabelTaskXAI
2022-12-14 22:26:00 | INFO | fairseq_cli.train | model: MusicBERTModel
2022-12-14 22:26:00 | INFO | fairseq_cli.train | criterion: MusicBERTM2PCriterionForXAI
2022-12-14 22:26:00 | INFO | fairseq_cli.train | num. model params: 22,805,730 (num. trained: 22,805,730)
2022-12-14 22:26:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-12-14 22:26:01 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 7.927 GB ; name = NVIDIA GeForce GTX 1080                 
2022-12-14 22:26:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-12-14 22:26:01 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-12-14 22:26:01 | INFO | fairseq_cli.train | max tokens per GPU = 32768 and batch size per GPU = 4
2022-12-14 22:26:01 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last_musicbert_small.pt
2022-12-14 22:26:01 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last_musicbert_small.pt
2022-12-14 22:26:01 | INFO | fairseq.trainer | loading train data for epoch 1
2022-12-14 22:26:01 | INFO | fairseq.data.data_utils | loaded 13,903 examples from: processed/xai_data_bin_apex_reg_cls_augmented/0/input0/train
dataset: 13903
labels: 13903
2022-12-14 22:26:01 | INFO | fairseq.trainer | begin training epoch 1
2022-12-14 22:26:15 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "3.505", "nll_loss": "0.137", "accuracy": "15.6", "wps": "5919.2", "ups": "7.25", "wpb": "815.9", "bsz": "32", "num_updates": "100", "lr": "3.33333e-05", "gnorm": "3.259", "train_wall": "14", "wall": "14"}
2022-12-14 22:26:29 | INFO | train_inner | {"epoch": 1, "update": 0.46, "loss": "2.928", "nll_loss": "0.115", "accuracy": "25.3", "wps": "6145.8", "ups": "7.52", "wpb": "817.1", "bsz": "32", "num_updates": "200", "lr": "6.66667e-05", "gnorm": "2.824", "train_wall": "13", "wall": "28"}
2022-12-14 22:26:42 | INFO | train_inner | {"epoch": 1, "update": 0.69, "loss": "2.871", "nll_loss": "0.113", "accuracy": "26.6", "wps": "5995.3", "ups": "7.34", "wpb": "816.4", "bsz": "32", "num_updates": "300", "lr": "0.0001", "gnorm": "3.136", "train_wall": "13", "wall": "41"}
2022-12-14 22:26:56 | INFO | train_inner | {"epoch": 1, "update": 0.92, "loss": "2.666", "nll_loss": "0.104", "accuracy": "32.5", "wps": "5817.9", "ups": "7.12", "wpb": "817", "bsz": "32", "num_updates": "400", "lr": "9.85075e-05", "gnorm": "4.351", "train_wall": "14", "wall": "55"}
2022-12-14 22:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:27:03 | INFO | valid | {"epoch": 1, "valid_loss": "2.455", "valid_nll_loss": "0.096", "valid_accuracy": "36.6", "valid_wps": "18056.7", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "435"}
2022-12-14 22:27:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 435 updates
2022-12-14 22:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 1 @ 435 updates, score 36.6) (writing took 69.0839812126942 seconds)
2022-12-14 22:28:12 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-12-14 22:28:12 | INFO | train | {"epoch": 1, "train_loss": "2.943", "train_nll_loss": "0.115", "train_accuracy": "26.1", "train_wps": "2710.7", "train_ups": "3.32", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "435", "train_lr": "9.79851e-05", "train_gnorm": "3.602", "train_train_wall": "59", "train_wall": "131"}
2022-12-14 22:28:12 | INFO | fairseq.trainer | begin training epoch 2
2022-12-14 22:28:21 | INFO | train_inner | {"epoch": 2, "update": 1.149, "loss": "2.272", "nll_loss": "0.089", "accuracy": "40.8", "wps": "963.2", "ups": "1.19", "wpb": "812.8", "bsz": "31.8", "num_updates": "500", "lr": "9.70149e-05", "gnorm": "6.681", "train_wall": "13", "wall": "140"}
2022-12-14 22:28:34 | INFO | train_inner | {"epoch": 2, "update": 1.379, "loss": "1.987", "nll_loss": "0.078", "accuracy": "49.8", "wps": "5969.2", "ups": "7.32", "wpb": "815.4", "bsz": "32", "num_updates": "600", "lr": "9.55224e-05", "gnorm": "9.006", "train_wall": "14", "wall": "153"}
2022-12-14 22:28:48 | INFO | train_inner | {"epoch": 2, "update": 1.609, "loss": "1.46", "nll_loss": "0.057", "accuracy": "64.3", "wps": "6195.5", "ups": "7.58", "wpb": "817.1", "bsz": "32", "num_updates": "700", "lr": "9.40299e-05", "gnorm": "10.534", "train_wall": "13", "wall": "167"}
2022-12-14 22:29:01 | INFO | train_inner | {"epoch": 2, "update": 1.839, "loss": "1.21", "nll_loss": "0.047", "accuracy": "71", "wps": "5915.8", "ups": "7.23", "wpb": "817.8", "bsz": "32", "num_updates": "800", "lr": "9.25373e-05", "gnorm": "12.241", "train_wall": "14", "wall": "181"}
2022-12-14 22:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:29:13 | INFO | valid | {"epoch": 2, "valid_loss": "0.651", "valid_nll_loss": "0.026", "valid_accuracy": "86.5", "valid_wps": "18012.3", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "870", "valid_best_accuracy": "86.5"}
2022-12-14 22:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 870 updates
2022-12-14 22:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 2 @ 870 updates, score 86.5) (writing took 68.9862225879915 seconds)
2022-12-14 22:30:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-12-14 22:30:23 | INFO | train | {"epoch": 2, "train_loss": "1.547", "train_nll_loss": "0.061", "train_accuracy": "61.7", "train_wps": "2729", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "870", "train_lr": "9.14925e-05", "train_gnorm": "10.302", "train_train_wall": "58", "train_wall": "261"}
2022-12-14 22:30:23 | INFO | fairseq.trainer | begin training epoch 3
2022-12-14 22:30:27 | INFO | train_inner | {"epoch": 3, "update": 2.069, "loss": "0.837", "nll_loss": "0.033", "accuracy": "81.5", "wps": "948.7", "ups": "1.17", "wpb": "812.1", "bsz": "31.8", "num_updates": "900", "lr": "9.10448e-05", "gnorm": "11.794", "train_wall": "13", "wall": "266"}
2022-12-14 22:30:41 | INFO | train_inner | {"epoch": 3, "update": 2.299, "loss": "0.52", "nll_loss": "0.02", "accuracy": "89.2", "wps": "6046.5", "ups": "7.4", "wpb": "817.4", "bsz": "32", "num_updates": "1000", "lr": "8.95522e-05", "gnorm": "10.502", "train_wall": "13", "wall": "280"}
2022-12-14 22:30:54 | INFO | train_inner | {"epoch": 3, "update": 2.529, "loss": "0.426", "nll_loss": "0.017", "accuracy": "91.2", "wps": "6185.5", "ups": "7.56", "wpb": "817.7", "bsz": "32", "num_updates": "1100", "lr": "8.80597e-05", "gnorm": "9.963", "train_wall": "13", "wall": "293"}
2022-12-14 22:31:08 | INFO | train_inner | {"epoch": 3, "update": 2.759, "loss": "0.348", "nll_loss": "0.014", "accuracy": "93", "wps": "5981.9", "ups": "7.33", "wpb": "816.2", "bsz": "32", "num_updates": "1200", "lr": "8.65672e-05", "gnorm": "9.797", "train_wall": "14", "wall": "307"}
2022-12-14 22:31:21 | INFO | train_inner | {"epoch": 3, "update": 2.989, "loss": "0.263", "nll_loss": "0.01", "accuracy": "95", "wps": "6160.2", "ups": "7.55", "wpb": "816.3", "bsz": "32", "num_updates": "1300", "lr": "8.50746e-05", "gnorm": "8.088", "train_wall": "13", "wall": "320"}
2022-12-14 22:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:31:24 | INFO | valid | {"epoch": 3, "valid_loss": "0.413", "valid_nll_loss": "0.016", "valid_accuracy": "92.4", "valid_wps": "17966.7", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "1305", "valid_best_accuracy": "92.4"}
2022-12-14 22:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1305 updates
2022-12-14 22:31:47 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:32:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 3 @ 1305 updates, score 92.4) (writing took 68.9767111139372 seconds)
2022-12-14 22:32:33 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-12-14 22:32:34 | INFO | train | {"epoch": 3, "train_loss": "0.411", "train_nll_loss": "0.016", "train_accuracy": "91.6", "train_wps": "2738.2", "train_ups": "3.36", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "1305", "train_lr": "8.5e-05", "train_gnorm": "9.717", "train_train_wall": "58", "train_wall": "392"}
2022-12-14 22:32:34 | INFO | fairseq.trainer | begin training epoch 4
2022-12-14 22:32:47 | INFO | train_inner | {"epoch": 4, "update": 3.218, "loss": "0.189", "nll_loss": "0.007", "accuracy": "96.4", "wps": "947.1", "ups": "1.17", "wpb": "811.5", "bsz": "31.8", "num_updates": "1400", "lr": "8.35821e-05", "gnorm": "7.271", "train_wall": "13", "wall": "406"}
2022-12-14 22:33:00 | INFO | train_inner | {"epoch": 4, "update": 3.448, "loss": "0.189", "nll_loss": "0.007", "accuracy": "96", "wps": "5959.6", "ups": "7.3", "wpb": "816.1", "bsz": "32", "num_updates": "1500", "lr": "8.20896e-05", "gnorm": "7.217", "train_wall": "14", "wall": "419"}
2022-12-14 22:33:14 | INFO | train_inner | {"epoch": 4, "update": 3.678, "loss": "0.209", "nll_loss": "0.008", "accuracy": "95.7", "wps": "6103.1", "ups": "7.46", "wpb": "817.8", "bsz": "32", "num_updates": "1600", "lr": "8.0597e-05", "gnorm": "8.173", "train_wall": "13", "wall": "433"}
2022-12-14 22:33:28 | INFO | train_inner | {"epoch": 4, "update": 3.908, "loss": "0.187", "nll_loss": "0.007", "accuracy": "96.2", "wps": "5667.4", "ups": "6.93", "wpb": "817.8", "bsz": "32", "num_updates": "1700", "lr": "7.91045e-05", "gnorm": "7.283", "train_wall": "14", "wall": "447"}
2022-12-14 22:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:33:36 | INFO | valid | {"epoch": 4, "valid_loss": "0.155", "valid_nll_loss": "0.006", "valid_accuracy": "97.9", "valid_wps": "17958.2", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "1740", "valid_best_accuracy": "97.9"}
2022-12-14 22:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1740 updates
2022-12-14 22:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:34:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 4 @ 1740 updates, score 97.9) (writing took 68.97745637502521 seconds)
2022-12-14 22:34:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-12-14 22:34:46 | INFO | train | {"epoch": 4, "train_loss": "0.189", "train_nll_loss": "0.007", "train_accuracy": "96.2", "train_wps": "2704.4", "train_ups": "3.32", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "1740", "train_lr": "7.85075e-05", "train_gnorm": "7.295", "train_train_wall": "59", "train_wall": "524"}
2022-12-14 22:34:46 | INFO | fairseq.trainer | begin training epoch 5
2022-12-14 22:34:54 | INFO | train_inner | {"epoch": 5, "update": 4.138, "loss": "0.136", "nll_loss": "0.005", "accuracy": "97.5", "wps": "950.1", "ups": "1.17", "wpb": "812.7", "bsz": "31.8", "num_updates": "1800", "lr": "7.76119e-05", "gnorm": "5.975", "train_wall": "13", "wall": "533"}
2022-12-14 22:35:08 | INFO | train_inner | {"epoch": 5, "update": 4.368, "loss": "0.161", "nll_loss": "0.006", "accuracy": "96.8", "wps": "5965.4", "ups": "7.3", "wpb": "817.1", "bsz": "32", "num_updates": "1900", "lr": "7.61194e-05", "gnorm": "7.486", "train_wall": "14", "wall": "547"}
2022-12-14 22:35:21 | INFO | train_inner | {"epoch": 5, "update": 4.598, "loss": "0.111", "nll_loss": "0.004", "accuracy": "97.8", "wps": "6152.2", "ups": "7.53", "wpb": "816.7", "bsz": "32", "num_updates": "2000", "lr": "7.46269e-05", "gnorm": "5.821", "train_wall": "13", "wall": "560"}
2022-12-14 22:35:34 | INFO | train_inner | {"epoch": 5, "update": 4.828, "loss": "0.113", "nll_loss": "0.004", "accuracy": "97.8", "wps": "6060.1", "ups": "7.43", "wpb": "815.8", "bsz": "32", "num_updates": "2100", "lr": "7.31343e-05", "gnorm": "5.249", "train_wall": "13", "wall": "573"}
2022-12-14 22:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:35:47 | INFO | valid | {"epoch": 5, "valid_loss": "0.176", "valid_nll_loss": "0.007", "valid_accuracy": "97", "valid_wps": "17950.8", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "2175", "valid_best_accuracy": "97.9"}
2022-12-14 22:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2175 updates
2022-12-14 22:36:10 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:36:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 5 @ 2175 updates, score 97.0) (writing took 23.234021874610335 seconds)
2022-12-14 22:36:10 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-12-14 22:36:11 | INFO | train | {"epoch": 5, "train_loss": "0.119", "train_nll_loss": "0.005", "train_accuracy": "97.7", "train_wps": "4221.4", "train_ups": "5.17", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "2175", "train_lr": "7.20149e-05", "train_gnorm": "5.8", "train_train_wall": "58", "train_wall": "609"}
2022-12-14 22:36:11 | INFO | fairseq.trainer | begin training epoch 6
2022-12-14 22:36:14 | INFO | train_inner | {"epoch": 6, "update": 5.057, "loss": "0.085", "nll_loss": "0.003", "accuracy": "98.4", "wps": "2047.6", "ups": "2.52", "wpb": "812.6", "bsz": "31.8", "num_updates": "2200", "lr": "7.16418e-05", "gnorm": "4.458", "train_wall": "13", "wall": "613"}
2022-12-14 22:36:28 | INFO | train_inner | {"epoch": 6, "update": 5.287, "loss": "0.07", "nll_loss": "0.003", "accuracy": "98.7", "wps": "6051.8", "ups": "7.4", "wpb": "817.5", "bsz": "32", "num_updates": "2300", "lr": "7.01493e-05", "gnorm": "4.273", "train_wall": "13", "wall": "627"}
2022-12-14 22:36:41 | INFO | train_inner | {"epoch": 6, "update": 5.517, "loss": "0.093", "nll_loss": "0.004", "accuracy": "98.1", "wps": "6278.8", "ups": "7.69", "wpb": "816.8", "bsz": "32", "num_updates": "2400", "lr": "6.86567e-05", "gnorm": "5.297", "train_wall": "13", "wall": "640"}
2022-12-14 22:36:54 | INFO | train_inner | {"epoch": 6, "update": 5.747, "loss": "0.093", "nll_loss": "0.004", "accuracy": "98", "wps": "6006", "ups": "7.36", "wpb": "816", "bsz": "32", "num_updates": "2500", "lr": "6.71642e-05", "gnorm": "5.228", "train_wall": "13", "wall": "653"}
2022-12-14 22:37:08 | INFO | train_inner | {"epoch": 6, "update": 5.977, "loss": "0.08", "nll_loss": "0.003", "accuracy": "98.4", "wps": "5814.7", "ups": "7.12", "wpb": "816.5", "bsz": "32", "num_updates": "2600", "lr": "6.56716e-05", "gnorm": "4.551", "train_wall": "14", "wall": "667"}
2022-12-14 22:37:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:37:12 | INFO | valid | {"epoch": 6, "valid_loss": "0.172", "valid_nll_loss": "0.007", "valid_accuracy": "97.2", "valid_wps": "17914.5", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "2610", "valid_best_accuracy": "97.9"}
2022-12-14 22:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2610 updates
2022-12-14 22:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 6 @ 2610 updates, score 97.2) (writing took 23.239039417356253 seconds)
2022-12-14 22:37:35 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-12-14 22:37:36 | INFO | train | {"epoch": 6, "train_loss": "0.084", "train_nll_loss": "0.003", "train_accuracy": "98.3", "train_wps": "4208.4", "train_ups": "5.16", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "2610", "train_lr": "6.55224e-05", "train_gnorm": "4.848", "train_train_wall": "58", "train_wall": "694"}
2022-12-14 22:37:36 | INFO | fairseq.trainer | begin training epoch 7
2022-12-14 22:37:48 | INFO | train_inner | {"epoch": 7, "update": 6.207, "loss": "0.043", "nll_loss": "0.002", "accuracy": "98.9", "wps": "2050.6", "ups": "2.52", "wpb": "812.8", "bsz": "31.8", "num_updates": "2700", "lr": "6.41791e-05", "gnorm": "3.741", "train_wall": "13", "wall": "707"}
2022-12-14 22:38:02 | INFO | train_inner | {"epoch": 7, "update": 6.437, "loss": "0.053", "nll_loss": "0.002", "accuracy": "98.9", "wps": "6005.4", "ups": "7.35", "wpb": "816.9", "bsz": "32", "num_updates": "2800", "lr": "6.26866e-05", "gnorm": "4.046", "train_wall": "13", "wall": "721"}
2022-12-14 22:38:15 | INFO | train_inner | {"epoch": 7, "update": 6.667, "loss": "0.041", "nll_loss": "0.002", "accuracy": "99.2", "wps": "5946.3", "ups": "7.29", "wpb": "816.1", "bsz": "32", "num_updates": "2900", "lr": "6.1194e-05", "gnorm": "3.054", "train_wall": "14", "wall": "734"}
2022-12-14 22:38:29 | INFO | train_inner | {"epoch": 7, "update": 6.897, "loss": "0.056", "nll_loss": "0.002", "accuracy": "98.9", "wps": "5941", "ups": "7.27", "wpb": "817.3", "bsz": "32", "num_updates": "3000", "lr": "5.97015e-05", "gnorm": "3.832", "train_wall": "14", "wall": "748"}
2022-12-14 22:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:38:37 | INFO | valid | {"epoch": 7, "valid_loss": "0.143", "valid_nll_loss": "0.006", "valid_accuracy": "97.9", "valid_wps": "17885.2", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3045", "valid_best_accuracy": "97.9"}
2022-12-14 22:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 3045 updates
2022-12-14 22:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 7 @ 3045 updates, score 97.9) (writing took 68.9812459461391 seconds)
2022-12-14 22:39:46 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-12-14 22:39:47 | INFO | train | {"epoch": 7, "train_loss": "0.051", "train_nll_loss": "0.002", "train_accuracy": "98.9", "train_wps": "2723.7", "train_ups": "3.34", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3045", "train_lr": "5.90299e-05", "train_gnorm": "3.67", "train_train_wall": "58", "train_wall": "825"}
2022-12-14 22:39:47 | INFO | fairseq.trainer | begin training epoch 8
2022-12-14 22:39:54 | INFO | train_inner | {"epoch": 8, "update": 7.126, "loss": "0.059", "nll_loss": "0.002", "accuracy": "98.8", "wps": "953.3", "ups": "1.17", "wpb": "812.6", "bsz": "31.8", "num_updates": "3100", "lr": "5.8209e-05", "gnorm": "3.782", "train_wall": "13", "wall": "834"}
2022-12-14 22:40:08 | INFO | train_inner | {"epoch": 8, "update": 7.356, "loss": "0.028", "nll_loss": "0.001", "accuracy": "99.2", "wps": "6071.1", "ups": "7.44", "wpb": "816.3", "bsz": "32", "num_updates": "3200", "lr": "5.67164e-05", "gnorm": "2.678", "train_wall": "13", "wall": "847"}
2022-12-14 22:40:22 | INFO | train_inner | {"epoch": 8, "update": 7.586, "loss": "0.041", "nll_loss": "0.002", "accuracy": "99.2", "wps": "5928.4", "ups": "7.26", "wpb": "817", "bsz": "32", "num_updates": "3300", "lr": "5.52239e-05", "gnorm": "3.279", "train_wall": "14", "wall": "861"}
2022-12-14 22:40:35 | INFO | train_inner | {"epoch": 8, "update": 7.816, "loss": "0.035", "nll_loss": "0.001", "accuracy": "99.2", "wps": "6000.2", "ups": "7.35", "wpb": "815.9", "bsz": "32", "num_updates": "3400", "lr": "5.37313e-05", "gnorm": "3.138", "train_wall": "13", "wall": "874"}
2022-12-14 22:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:40:48 | INFO | valid | {"epoch": 8, "valid_loss": "0.126", "valid_nll_loss": "0.005", "valid_accuracy": "98.3", "valid_wps": "17911.8", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3480", "valid_best_accuracy": "98.3"}
2022-12-14 22:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3480 updates
2022-12-14 22:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 8 @ 3480 updates, score 98.3) (writing took 68.96803776500747 seconds)
2022-12-14 22:41:57 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-12-14 22:41:58 | INFO | train | {"epoch": 8, "train_loss": "0.039", "train_nll_loss": "0.002", "train_accuracy": "99.1", "train_wps": "2732.2", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3480", "train_lr": "5.25373e-05", "train_gnorm": "3.287", "train_train_wall": "58", "train_wall": "956"}
2022-12-14 22:41:58 | INFO | fairseq.trainer | begin training epoch 9
2022-12-14 22:42:01 | INFO | train_inner | {"epoch": 9, "update": 8.046, "loss": "0.041", "nll_loss": "0.002", "accuracy": "99", "wps": "951.4", "ups": "1.17", "wpb": "812.8", "bsz": "31.8", "num_updates": "3500", "lr": "5.22388e-05", "gnorm": "3.334", "train_wall": "13", "wall": "960"}
2022-12-14 22:42:14 | INFO | train_inner | {"epoch": 9, "update": 8.276, "loss": "0.014", "nll_loss": "0.001", "accuracy": "99.8", "wps": "6201.4", "ups": "7.59", "wpb": "817.3", "bsz": "32", "num_updates": "3600", "lr": "5.07463e-05", "gnorm": "1.107", "train_wall": "13", "wall": "973"}
2022-12-14 22:42:28 | INFO | train_inner | {"epoch": 9, "update": 8.506, "loss": "0.027", "nll_loss": "0.001", "accuracy": "99.4", "wps": "6053.2", "ups": "7.41", "wpb": "816.7", "bsz": "32", "num_updates": "3700", "lr": "4.92537e-05", "gnorm": "2.388", "train_wall": "13", "wall": "987"}
2022-12-14 22:42:41 | INFO | train_inner | {"epoch": 9, "update": 8.736, "loss": "0.021", "nll_loss": "0.001", "accuracy": "99.6", "wps": "5964.9", "ups": "7.31", "wpb": "816", "bsz": "32", "num_updates": "3800", "lr": "4.77612e-05", "gnorm": "2.252", "train_wall": "14", "wall": "1000"}
2022-12-14 22:42:55 | INFO | train_inner | {"epoch": 9, "update": 8.966, "loss": "0.047", "nll_loss": "0.002", "accuracy": "99.1", "wps": "6109.1", "ups": "7.48", "wpb": "817", "bsz": "32", "num_updates": "3900", "lr": "4.62687e-05", "gnorm": "3.448", "train_wall": "13", "wall": "1014"}
2022-12-14 22:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:42:59 | INFO | valid | {"epoch": 9, "valid_loss": "0.128", "valid_nll_loss": "0.005", "valid_accuracy": "98.4", "valid_wps": "17961.8", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3915", "valid_best_accuracy": "98.4"}
2022-12-14 22:42:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3915 updates
2022-12-14 22:43:22 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 9 @ 3915 updates, score 98.4) (writing took 68.97587694507092 seconds)
2022-12-14 22:44:08 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-12-14 22:44:09 | INFO | train | {"epoch": 9, "train_loss": "0.027", "train_nll_loss": "0.001", "train_accuracy": "99.4", "train_wps": "2731.4", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3915", "train_lr": "4.60448e-05", "train_gnorm": "2.294", "train_train_wall": "58", "train_wall": "1087"}
2022-12-14 22:44:09 | INFO | fairseq.trainer | begin training epoch 10
2022-12-14 22:44:21 | INFO | train_inner | {"epoch": 10, "update": 9.195, "loss": "0.023", "nll_loss": "0.001", "accuracy": "99.4", "wps": "946.7", "ups": "1.17", "wpb": "812.6", "bsz": "31.8", "num_updates": "4000", "lr": "4.47761e-05", "gnorm": "2.174", "train_wall": "13", "wall": "1100"}
2022-12-14 22:44:34 | INFO | train_inner | {"epoch": 10, "update": 9.425, "loss": "0.014", "nll_loss": "0.001", "accuracy": "99.8", "wps": "6180.8", "ups": "7.56", "wpb": "817.3", "bsz": "32", "num_updates": "4100", "lr": "4.32836e-05", "gnorm": "1.608", "train_wall": "13", "wall": "1113"}
2022-12-14 22:44:47 | INFO | train_inner | {"epoch": 10, "update": 9.655, "loss": "0.02", "nll_loss": "0.001", "accuracy": "99.6", "wps": "6130.3", "ups": "7.5", "wpb": "817.2", "bsz": "32", "num_updates": "4200", "lr": "4.1791e-05", "gnorm": "1.754", "train_wall": "13", "wall": "1126"}
2022-12-14 22:45:01 | INFO | train_inner | {"epoch": 10, "update": 9.885, "loss": "0.026", "nll_loss": "0.001", "accuracy": "99.5", "wps": "5866.3", "ups": "7.19", "wpb": "816.4", "bsz": "32", "num_updates": "4300", "lr": "4.02985e-05", "gnorm": "2.11", "train_wall": "14", "wall": "1140"}
2022-12-14 22:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:45:10 | INFO | valid | {"epoch": 10, "valid_loss": "0.13", "valid_nll_loss": "0.005", "valid_accuracy": "98.4", "valid_wps": "17839", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "4350", "valid_best_accuracy": "98.4"}
2022-12-14 22:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4350 updates
2022-12-14 22:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:46:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 10 @ 4350 updates, score 98.4) (writing took 68.97200625389814 seconds)
2022-12-14 22:46:19 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-12-14 22:46:20 | INFO | train | {"epoch": 10, "train_loss": "0.02", "train_nll_loss": "0.001", "train_accuracy": "99.6", "train_wps": "2726.5", "train_ups": "3.34", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "4350", "train_lr": "3.95522e-05", "train_gnorm": "1.907", "train_train_wall": "58", "train_wall": "1218"}
2022-12-14 22:46:20 | INFO | fairseq.trainer | begin training epoch 11
2022-12-14 22:46:27 | INFO | train_inner | {"epoch": 11, "update": 10.115, "loss": "0.018", "nll_loss": "0.001", "accuracy": "99.5", "wps": "947", "ups": "1.17", "wpb": "812.3", "bsz": "31.8", "num_updates": "4400", "lr": "3.8806e-05", "gnorm": "2.303", "train_wall": "13", "wall": "1226"}
2022-12-14 22:46:41 | INFO | train_inner | {"epoch": 11, "update": 10.345, "loss": "0.008", "nll_loss": "0", "accuracy": "99.9", "wps": "5983.1", "ups": "7.32", "wpb": "816.9", "bsz": "32", "num_updates": "4500", "lr": "3.73134e-05", "gnorm": "0.996", "train_wall": "14", "wall": "1240"}
2022-12-14 22:46:54 | INFO | train_inner | {"epoch": 11, "update": 10.575, "loss": "0.004", "nll_loss": "0", "accuracy": "99.9", "wps": "6253.9", "ups": "7.65", "wpb": "817.2", "bsz": "32", "num_updates": "4600", "lr": "3.58209e-05", "gnorm": "0.634", "train_wall": "13", "wall": "1253"}
2022-12-14 22:47:07 | INFO | train_inner | {"epoch": 11, "update": 10.805, "loss": "0.014", "nll_loss": "0.001", "accuracy": "99.6", "wps": "6159.7", "ups": "7.54", "wpb": "816.8", "bsz": "32", "num_updates": "4700", "lr": "3.43284e-05", "gnorm": "1.801", "train_wall": "13", "wall": "1266"}
2022-12-14 22:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:47:21 | INFO | valid | {"epoch": 11, "valid_loss": "0.117", "valid_nll_loss": "0.005", "valid_accuracy": "98.4", "valid_wps": "17962.9", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "4785", "valid_best_accuracy": "98.4"}
2022-12-14 22:47:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4785 updates
2022-12-14 22:47:44 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 11 @ 4785 updates, score 98.4) (writing took 68.97716000443324 seconds)
2022-12-14 22:48:30 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-12-14 22:48:31 | INFO | train | {"epoch": 11, "train_loss": "0.011", "train_nll_loss": "0", "train_accuracy": "99.7", "train_wps": "2729.9", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "4785", "train_lr": "3.30597e-05", "train_gnorm": "1.417", "train_train_wall": "58", "train_wall": "1349"}
2022-12-14 22:48:31 | INFO | fairseq.trainer | begin training epoch 12
2022-12-14 22:48:33 | INFO | train_inner | {"epoch": 12, "update": 11.034, "loss": "0.012", "nll_loss": "0", "accuracy": "99.7", "wps": "942.5", "ups": "1.16", "wpb": "811.6", "bsz": "31.8", "num_updates": "4800", "lr": "3.28358e-05", "gnorm": "1.739", "train_wall": "14", "wall": "1352"}
2022-12-14 22:48:47 | INFO | train_inner | {"epoch": 12, "update": 11.264, "loss": "0.014", "nll_loss": "0.001", "accuracy": "99.6", "wps": "6095.6", "ups": "7.46", "wpb": "816.6", "bsz": "32", "num_updates": "4900", "lr": "3.13433e-05", "gnorm": "1.861", "train_wall": "13", "wall": "1366"}
2022-12-14 22:49:00 | INFO | train_inner | {"epoch": 12, "update": 11.494, "loss": "0.009", "nll_loss": "0", "accuracy": "99.8", "wps": "6098.2", "ups": "7.46", "wpb": "817", "bsz": "32", "num_updates": "5000", "lr": "2.98507e-05", "gnorm": "0.999", "train_wall": "13", "wall": "1379"}
2022-12-14 22:49:14 | INFO | train_inner | {"epoch": 12, "update": 11.724, "loss": "0.005", "nll_loss": "0", "accuracy": "99.9", "wps": "5974.1", "ups": "7.32", "wpb": "816.2", "bsz": "32", "num_updates": "5100", "lr": "2.83582e-05", "gnorm": "0.672", "train_wall": "14", "wall": "1393"}
2022-12-14 22:49:27 | INFO | train_inner | {"epoch": 12, "update": 11.954, "loss": "0.01", "nll_loss": "0", "accuracy": "99.8", "wps": "6177.6", "ups": "7.56", "wpb": "817.2", "bsz": "32", "num_updates": "5200", "lr": "2.68657e-05", "gnorm": "1.433", "train_wall": "13", "wall": "1406"}
2022-12-14 22:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:49:32 | INFO | valid | {"epoch": 12, "valid_loss": "0.12", "valid_nll_loss": "0.005", "valid_accuracy": "98.3", "valid_wps": "17872.2", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "5220", "valid_best_accuracy": "98.4"}
2022-12-14 22:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 5220 updates
2022-12-14 22:49:55 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 12 @ 5220 updates, score 98.3) (writing took 23.2293195319362 seconds)
2022-12-14 22:49:55 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-12-14 22:49:56 | INFO | train | {"epoch": 12, "train_loss": "0.009", "train_nll_loss": "0", "train_accuracy": "99.8", "train_wps": "4216.9", "train_ups": "5.17", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "5220", "train_lr": "2.65672e-05", "train_gnorm": "1.236", "train_train_wall": "58", "train_wall": "1434"}
2022-12-14 22:49:56 | INFO | fairseq.trainer | begin training epoch 13
2022-12-14 22:50:07 | INFO | train_inner | {"epoch": 13, "update": 12.184, "loss": "0.003", "nll_loss": "0", "accuracy": "99.9", "wps": "2043.6", "ups": "2.52", "wpb": "811.9", "bsz": "31.8", "num_updates": "5300", "lr": "2.53731e-05", "gnorm": "0.485", "train_wall": "13", "wall": "1446"}
2022-12-14 22:50:20 | INFO | train_inner | {"epoch": 13, "update": 12.414, "loss": "0.006", "nll_loss": "0", "accuracy": "99.8", "wps": "5983.2", "ups": "7.32", "wpb": "817.2", "bsz": "32", "num_updates": "5400", "lr": "2.38806e-05", "gnorm": "0.936", "train_wall": "14", "wall": "1460"}
2022-12-14 22:50:34 | INFO | train_inner | {"epoch": 13, "update": 12.644, "loss": "0.001", "nll_loss": "0", "accuracy": "100", "wps": "6101.1", "ups": "7.46", "wpb": "817.9", "bsz": "32", "num_updates": "5500", "lr": "2.23881e-05", "gnorm": "0.187", "train_wall": "13", "wall": "1473"}
2022-12-14 22:50:47 | INFO | train_inner | {"epoch": 13, "update": 12.874, "loss": "0.006", "nll_loss": "0", "accuracy": "99.9", "wps": "6193.9", "ups": "7.59", "wpb": "816.5", "bsz": "32", "num_updates": "5600", "lr": "2.08955e-05", "gnorm": "0.636", "train_wall": "13", "wall": "1486"}
2022-12-14 22:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:50:57 | INFO | valid | {"epoch": 13, "valid_loss": "0.1", "valid_nll_loss": "0.004", "valid_accuracy": "98.6", "valid_wps": "17896.9", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "5655", "valid_best_accuracy": "98.6"}
2022-12-14 22:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5655 updates
2022-12-14 22:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 13 @ 5655 updates, score 98.6) (writing took 68.9699916401878 seconds)
2022-12-14 22:52:06 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-12-14 22:52:07 | INFO | train | {"epoch": 13, "train_loss": "0.004", "train_nll_loss": "0", "train_accuracy": "99.9", "train_wps": "2730.3", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "5655", "train_lr": "2.00746e-05", "train_gnorm": "0.504", "train_train_wall": "58", "train_wall": "1565"}
2022-12-14 22:52:07 | INFO | fairseq.trainer | begin training epoch 14
2022-12-14 22:52:13 | INFO | train_inner | {"epoch": 14, "update": 13.103, "loss": "0.002", "nll_loss": "0", "accuracy": "100", "wps": "945.2", "ups": "1.16", "wpb": "811.5", "bsz": "31.8", "num_updates": "5700", "lr": "1.9403e-05", "gnorm": "0.264", "train_wall": "14", "wall": "1572"}
2022-12-14 22:52:27 | INFO | train_inner | {"epoch": 14, "update": 13.333, "loss": "0.005", "nll_loss": "0", "accuracy": "99.9", "wps": "5941.3", "ups": "7.27", "wpb": "817.4", "bsz": "32", "num_updates": "5800", "lr": "1.79104e-05", "gnorm": "0.392", "train_wall": "14", "wall": "1586"}
2022-12-14 22:52:41 | INFO | train_inner | {"epoch": 14, "update": 13.563, "loss": "0.001", "nll_loss": "0", "accuracy": "100", "wps": "5821.1", "ups": "7.13", "wpb": "816.2", "bsz": "32", "num_updates": "5900", "lr": "1.64179e-05", "gnorm": "0.242", "train_wall": "14", "wall": "1600"}
2022-12-14 22:52:55 | INFO | train_inner | {"epoch": 14, "update": 13.793, "loss": "0.003", "nll_loss": "0", "accuracy": "100", "wps": "5961.7", "ups": "7.29", "wpb": "817.5", "bsz": "32", "num_updates": "6000", "lr": "1.49254e-05", "gnorm": "0.337", "train_wall": "14", "wall": "1614"}
2022-12-14 22:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:53:10 | INFO | valid | {"epoch": 14, "valid_loss": "0.104", "valid_nll_loss": "0.004", "valid_accuracy": "98.6", "valid_wps": "17836.7", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6090", "valid_best_accuracy": "98.6"}
2022-12-14 22:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 6090 updates
2022-12-14 22:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:54:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 14 @ 6090 updates, score 98.6) (writing took 68.97309364331886 seconds)
2022-12-14 22:54:19 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-12-14 22:54:20 | INFO | train | {"epoch": 14, "train_loss": "0.002", "train_nll_loss": "0", "train_accuracy": "100", "train_wps": "2692.2", "train_ups": "3.3", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6090", "train_lr": "1.35821e-05", "train_gnorm": "0.25", "train_train_wall": "60", "train_wall": "1698"}
2022-12-14 22:54:20 | INFO | fairseq.trainer | begin training epoch 15
2022-12-14 22:54:21 | INFO | train_inner | {"epoch": 15, "update": 14.023, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "940", "ups": "1.16", "wpb": "812.2", "bsz": "31.8", "num_updates": "6100", "lr": "1.34328e-05", "gnorm": "0.06", "train_wall": "14", "wall": "1700"}
2022-12-14 22:54:35 | INFO | train_inner | {"epoch": 15, "update": 14.253, "loss": "0.001", "nll_loss": "0", "accuracy": "100", "wps": "6086.8", "ups": "7.45", "wpb": "817", "bsz": "32", "num_updates": "6200", "lr": "1.19403e-05", "gnorm": "0.193", "train_wall": "13", "wall": "1714"}
2022-12-14 22:54:48 | INFO | train_inner | {"epoch": 15, "update": 14.483, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "6034.4", "ups": "7.4", "wpb": "816", "bsz": "32", "num_updates": "6300", "lr": "1.04478e-05", "gnorm": "0.058", "train_wall": "13", "wall": "1727"}
2022-12-14 22:55:02 | INFO | train_inner | {"epoch": 15, "update": 14.713, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "6072.2", "ups": "7.43", "wpb": "817.5", "bsz": "32", "num_updates": "6400", "lr": "8.95522e-06", "gnorm": "0.022", "train_wall": "13", "wall": "1741"}
2022-12-14 22:55:15 | INFO | train_inner | {"epoch": 15, "update": 14.943, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "5934.2", "ups": "7.27", "wpb": "816.1", "bsz": "32", "num_updates": "6500", "lr": "7.46269e-06", "gnorm": "0.036", "train_wall": "14", "wall": "1754"}
2022-12-14 22:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:55:21 | INFO | valid | {"epoch": 15, "valid_loss": "0.095", "valid_nll_loss": "0.004", "valid_accuracy": "98.6", "valid_wps": "17958", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6525", "valid_best_accuracy": "98.6"}
2022-12-14 22:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6525 updates
2022-12-14 22:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 15 @ 6525 updates, score 98.6) (writing took 68.96723746927455 seconds)
2022-12-14 22:56:30 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-12-14 22:56:31 | INFO | train | {"epoch": 15, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "100", "train_wps": "2719.6", "train_ups": "3.33", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6525", "train_lr": "7.08955e-06", "train_gnorm": "0.074", "train_train_wall": "58", "train_wall": "1829"}
2022-12-14 22:56:31 | INFO | fairseq.trainer | begin training epoch 16
2022-12-14 22:56:41 | INFO | train_inner | {"epoch": 16, "update": 15.172, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "948.1", "ups": "1.17", "wpb": "812.6", "bsz": "31.8", "num_updates": "6600", "lr": "5.97015e-06", "gnorm": "0.044", "train_wall": "13", "wall": "1840"}
2022-12-14 22:56:55 | INFO | train_inner | {"epoch": 16, "update": 15.402, "loss": "0.001", "nll_loss": "0", "accuracy": "100", "wps": "6098.9", "ups": "7.47", "wpb": "816.4", "bsz": "32", "num_updates": "6700", "lr": "4.47761e-06", "gnorm": "0.141", "train_wall": "13", "wall": "1854"}
2022-12-14 22:57:08 | INFO | train_inner | {"epoch": 16, "update": 15.632, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "6078.9", "ups": "7.44", "wpb": "816.8", "bsz": "32", "num_updates": "6800", "lr": "2.98507e-06", "gnorm": "0.086", "train_wall": "13", "wall": "1867"}
2022-12-14 22:57:22 | INFO | train_inner | {"epoch": 16, "update": 15.862, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "5998.9", "ups": "7.34", "wpb": "817", "bsz": "32", "num_updates": "6900", "lr": "1.49254e-06", "gnorm": "0.072", "train_wall": "13", "wall": "1881"}
2022-12-14 22:57:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:57:32 | INFO | valid | {"epoch": 16, "valid_loss": "0.094", "valid_nll_loss": "0.004", "valid_accuracy": "98.6", "valid_wps": "17857.1", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6960", "valid_best_accuracy": "98.6"}
2022-12-14 22:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6960 updates
2022-12-14 22:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 16 @ 6960 updates, score 98.6) (writing took 68.98056028503925 seconds)
2022-12-14 22:58:41 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-12-14 22:58:42 | INFO | train | {"epoch": 16, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "100", "train_wps": "2730.5", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6960", "train_lr": "5.97015e-07", "train_gnorm": "0.08", "train_train_wall": "58", "train_wall": "1960"}
2022-12-14 22:58:42 | INFO | fairseq.trainer | begin training epoch 17
2022-12-14 22:58:47 | INFO | train_inner | {"epoch": 17, "update": 16.092, "loss": "0", "nll_loss": "0", "accuracy": "100", "wps": "949.6", "ups": "1.17", "wpb": "813.1", "bsz": "31.8", "num_updates": "7000", "lr": "0", "gnorm": "0.035", "train_wall": "13", "wall": "1966"}
2022-12-14 22:58:47 | INFO | fairseq_cli.train | Stopping training due to num_updates: 7000 >= max_update: 7000
2022-12-14 22:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 22:58:50 | INFO | valid | {"epoch": 17, "valid_loss": "0.094", "valid_nll_loss": "0.004", "valid_accuracy": "98.6", "valid_wps": "17959.6", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "7000", "valid_best_accuracy": "98.6"}
2022-12-14 22:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 7000 updates
2022-12-14 22:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt
2022-12-14 22:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-4_small_tmp.pt.pt (epoch 17 @ 7000 updates, score 98.6) (writing took 68.96121082408354 seconds)
2022-12-14 22:59:59 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-12-14 22:59:59 | INFO | train | {"epoch": 17, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "100", "train_wps": "426.6", "train_ups": "0.52", "train_wpb": "817.2", "train_bsz": "32", "train_num_updates": "7000", "train_lr": "0", "train_gnorm": "0.066", "train_train_wall": "5", "train_wall": "2038"}
2022-12-14 22:59:59 | INFO | fairseq_cli.train | done training in 2038.3 seconds
disable_cp = False
mask_strategy = ['bar']
convert_encoding = OCTMIDI
crop_length = None
2022-12-14 23:00:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'tensorboard_logdir': 'checkpoints/board_apex_M2P_1e-5_small_tmp', 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': 'musicbert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': 4, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 7000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoints/checkpoint_last_musicbert_small.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '_xai_apex_M2P_1e-5_small_tmp.pt', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='musicbert_small', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-5_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-5_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'task': Namespace(_name='xai', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-5_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-5_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'criterion': Namespace(_name='M2P_xai', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-5_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-5_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 300, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 7000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}
2022-12-14 23:00:09 | INFO | musicbert | [input] dictionary: 1237 types
2022-12-14 23:00:09 | INFO | musicbert | [label] dictionary: 497 types
2022-12-14 23:00:09 | INFO | fairseq.data.data_utils | loaded 1,545 examples from: processed/xai_data_bin_apex_reg_cls_augmented/0/input0/valid
dataset: 1545
labels: 1545
2022-12-14 23:00:09 | INFO | fairseq_cli.train | MusicBERTModel(
  (encoder): MusicBERTEncoder(
    (sentence_encoder): OctupleEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(1237, 512, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(8194, 512, padding_idx=1)
      (emb_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (downsampling): Sequential(
        (0): Linear(in_features=4096, out_features=512, bias=True)
      )
      (upsampling): Sequential(
        (0): Linear(in_features=512, out_features=4096, bias=True)
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=512, out_features=512, bias=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict(
    (xai_head): RobertaClassificationHead(
      (dense): Linear(in_features=512, out_features=512, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (out_proj): Linear(in_features=512, out_features=13, bias=True)
    )
  )
  (regression_heads): ModuleDict()
)
2022-12-14 23:00:09 | INFO | fairseq_cli.train | task: MusicBERTSentencePredictionMultilabelTaskXAI
2022-12-14 23:00:09 | INFO | fairseq_cli.train | model: MusicBERTModel
2022-12-14 23:00:09 | INFO | fairseq_cli.train | criterion: MusicBERTM2PCriterionForXAI
2022-12-14 23:00:09 | INFO | fairseq_cli.train | num. model params: 22,805,730 (num. trained: 22,805,730)
2022-12-14 23:00:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-12-14 23:00:10 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 7.927 GB ; name = NVIDIA GeForce GTX 1080                 
2022-12-14 23:00:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-12-14 23:00:10 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-12-14 23:00:10 | INFO | fairseq_cli.train | max tokens per GPU = 32768 and batch size per GPU = 4
2022-12-14 23:00:10 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last_musicbert_small.pt
2022-12-14 23:00:10 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last_musicbert_small.pt
2022-12-14 23:00:10 | INFO | fairseq.trainer | loading train data for epoch 1
2022-12-14 23:00:10 | INFO | fairseq.data.data_utils | loaded 13,903 examples from: processed/xai_data_bin_apex_reg_cls_augmented/0/input0/train
dataset: 13903
labels: 13903
2022-12-14 23:00:10 | INFO | fairseq.trainer | begin training epoch 1
2022-12-14 23:00:24 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "3.687", "nll_loss": "0.145", "accuracy": "9.3", "wps": "5939.8", "ups": "7.28", "wpb": "815.9", "bsz": "32", "num_updates": "100", "lr": "3.33333e-06", "gnorm": "3.266", "train_wall": "14", "wall": "14"}
2022-12-14 23:00:38 | INFO | train_inner | {"epoch": 1, "update": 0.46, "loss": "3.571", "nll_loss": "0.14", "accuracy": "19.3", "wps": "6121.3", "ups": "7.49", "wpb": "817.1", "bsz": "32", "num_updates": "200", "lr": "6.66667e-06", "gnorm": "3.09", "train_wall": "13", "wall": "28"}
2022-12-14 23:00:51 | INFO | train_inner | {"epoch": 1, "update": 0.69, "loss": "3.2", "nll_loss": "0.125", "accuracy": "23", "wps": "5965.2", "ups": "7.31", "wpb": "816.4", "bsz": "32", "num_updates": "300", "lr": "1e-05", "gnorm": "3.202", "train_wall": "14", "wall": "41"}
2022-12-14 23:01:06 | INFO | train_inner | {"epoch": 1, "update": 0.92, "loss": "2.97", "nll_loss": "0.116", "accuracy": "24.2", "wps": "5817.1", "ups": "7.12", "wpb": "817", "bsz": "32", "num_updates": "400", "lr": "9.85075e-06", "gnorm": "2.917", "train_wall": "14", "wall": "55"}
2022-12-14 23:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:01:12 | INFO | valid | {"epoch": 1, "valid_loss": "2.93", "valid_nll_loss": "0.115", "valid_accuracy": "22.1", "valid_wps": "17973.3", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "435"}
2022-12-14 23:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 435 updates
2022-12-14 23:01:36 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 1 @ 435 updates, score 22.1) (writing took 68.90085209999233 seconds)
2022-12-14 23:02:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-12-14 23:02:21 | INFO | train | {"epoch": 1, "train_loss": "3.315", "train_nll_loss": "0.13", "train_accuracy": "19.5", "train_wps": "2710.9", "train_ups": "3.32", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "435", "train_lr": "9.79851e-06", "train_gnorm": "3.091", "train_train_wall": "59", "train_wall": "131"}
2022-12-14 23:02:21 | INFO | fairseq.trainer | begin training epoch 2
2022-12-14 23:02:30 | INFO | train_inner | {"epoch": 2, "update": 1.149, "loss": "2.895", "nll_loss": "0.113", "accuracy": "25.8", "wps": "964.5", "ups": "1.19", "wpb": "812.8", "bsz": "31.8", "num_updates": "500", "lr": "9.70149e-06", "gnorm": "2.877", "train_wall": "13", "wall": "140"}
2022-12-14 23:02:44 | INFO | train_inner | {"epoch": 2, "update": 1.379, "loss": "2.904", "nll_loss": "0.114", "accuracy": "25.2", "wps": "5982.5", "ups": "7.34", "wpb": "815.4", "bsz": "32", "num_updates": "600", "lr": "9.55224e-06", "gnorm": "2.931", "train_wall": "13", "wall": "153"}
2022-12-14 23:02:57 | INFO | train_inner | {"epoch": 2, "update": 1.609, "loss": "2.789", "nll_loss": "0.109", "accuracy": "29.5", "wps": "6230.8", "ups": "7.63", "wpb": "817.1", "bsz": "32", "num_updates": "700", "lr": "9.40299e-06", "gnorm": "3.105", "train_wall": "13", "wall": "167"}
2022-12-14 23:03:10 | INFO | train_inner | {"epoch": 2, "update": 1.839, "loss": "2.818", "nll_loss": "0.11", "accuracy": "28.1", "wps": "5956.8", "ups": "7.28", "wpb": "817.8", "bsz": "32", "num_updates": "800", "lr": "9.25373e-06", "gnorm": "3.943", "train_wall": "14", "wall": "180"}
2022-12-14 23:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:03:22 | INFO | valid | {"epoch": 2, "valid_loss": "2.779", "valid_nll_loss": "0.109", "valid_accuracy": "29.9", "valid_wps": "17996", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "870", "valid_best_accuracy": "29.9"}
2022-12-14 23:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 870 updates
2022-12-14 23:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:04:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 2 @ 870 updates, score 29.9) (writing took 68.97363023413345 seconds)
2022-12-14 23:04:31 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-12-14 23:04:32 | INFO | train | {"epoch": 2, "train_loss": "2.832", "train_nll_loss": "0.111", "train_accuracy": "28.1", "train_wps": "2735.9", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "870", "train_lr": "9.14925e-06", "train_gnorm": "3.456", "train_train_wall": "58", "train_wall": "261"}
2022-12-14 23:04:32 | INFO | fairseq.trainer | begin training epoch 3
2022-12-14 23:04:36 | INFO | train_inner | {"epoch": 3, "update": 2.069, "loss": "2.716", "nll_loss": "0.106", "accuracy": "32.5", "wps": "950.3", "ups": "1.17", "wpb": "812.1", "bsz": "31.8", "num_updates": "900", "lr": "9.10448e-06", "gnorm": "4.602", "train_wall": "13", "wall": "266"}
2022-12-14 23:04:50 | INFO | train_inner | {"epoch": 3, "update": 2.299, "loss": "2.648", "nll_loss": "0.104", "accuracy": "34.4", "wps": "6027.1", "ups": "7.37", "wpb": "817.4", "bsz": "32", "num_updates": "1000", "lr": "8.95522e-06", "gnorm": "5.961", "train_wall": "13", "wall": "279"}
2022-12-14 23:05:03 | INFO | train_inner | {"epoch": 3, "update": 2.529, "loss": "2.594", "nll_loss": "0.102", "accuracy": "34.4", "wps": "6184.6", "ups": "7.56", "wpb": "817.7", "bsz": "32", "num_updates": "1100", "lr": "8.80597e-06", "gnorm": "6.163", "train_wall": "13", "wall": "293"}
2022-12-14 23:05:16 | INFO | train_inner | {"epoch": 3, "update": 2.759, "loss": "2.515", "nll_loss": "0.099", "accuracy": "37.9", "wps": "5984.7", "ups": "7.33", "wpb": "816.2", "bsz": "32", "num_updates": "1200", "lr": "8.65672e-06", "gnorm": "7.852", "train_wall": "13", "wall": "306"}
2022-12-14 23:05:30 | INFO | train_inner | {"epoch": 3, "update": 2.989, "loss": "2.492", "nll_loss": "0.098", "accuracy": "38.1", "wps": "6130.1", "ups": "7.51", "wpb": "816.3", "bsz": "32", "num_updates": "1300", "lr": "8.50746e-06", "gnorm": "8.297", "train_wall": "13", "wall": "320"}
2022-12-14 23:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:05:33 | INFO | valid | {"epoch": 3, "valid_loss": "2.537", "valid_nll_loss": "0.1", "valid_accuracy": "33", "valid_wps": "18022.2", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "1305", "valid_best_accuracy": "33"}
2022-12-14 23:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1305 updates
2022-12-14 23:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 3 @ 1305 updates, score 33.0) (writing took 68.96468077320606 seconds)
2022-12-14 23:06:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-12-14 23:06:43 | INFO | train | {"epoch": 3, "train_loss": "2.574", "train_nll_loss": "0.101", "train_accuracy": "36", "train_wps": "2736", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "1305", "train_lr": "8.5e-06", "train_gnorm": "6.991", "train_train_wall": "58", "train_wall": "392"}
2022-12-14 23:06:43 | INFO | fairseq.trainer | begin training epoch 4
2022-12-14 23:06:55 | INFO | train_inner | {"epoch": 4, "update": 3.218, "loss": "2.47", "nll_loss": "0.097", "accuracy": "37.7", "wps": "947.5", "ups": "1.17", "wpb": "811.5", "bsz": "31.8", "num_updates": "1400", "lr": "8.35821e-06", "gnorm": "10.057", "train_wall": "13", "wall": "405"}
2022-12-14 23:07:09 | INFO | train_inner | {"epoch": 4, "update": 3.448, "loss": "2.353", "nll_loss": "0.092", "accuracy": "41.3", "wps": "6217.5", "ups": "7.62", "wpb": "816.1", "bsz": "32", "num_updates": "1500", "lr": "8.20896e-06", "gnorm": "11.11", "train_wall": "13", "wall": "419"}
2022-12-14 23:07:22 | INFO | train_inner | {"epoch": 4, "update": 3.678, "loss": "2.344", "nll_loss": "0.092", "accuracy": "42.1", "wps": "6084.8", "ups": "7.44", "wpb": "817.8", "bsz": "32", "num_updates": "1600", "lr": "8.0597e-06", "gnorm": "11.208", "train_wall": "13", "wall": "432"}
2022-12-14 23:07:36 | INFO | train_inner | {"epoch": 4, "update": 3.908, "loss": "2.255", "nll_loss": "0.088", "accuracy": "43.5", "wps": "5788.4", "ups": "7.08", "wpb": "817.8", "bsz": "32", "num_updates": "1700", "lr": "7.91045e-06", "gnorm": "11.951", "train_wall": "14", "wall": "446"}
2022-12-14 23:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:07:44 | INFO | valid | {"epoch": 4, "valid_loss": "2.271", "valid_nll_loss": "0.089", "valid_accuracy": "41.5", "valid_wps": "17984.6", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "1740", "valid_best_accuracy": "41.5"}
2022-12-14 23:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1740 updates
2022-12-14 23:08:07 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 4 @ 1740 updates, score 41.5) (writing took 68.9973634746857 seconds)
2022-12-14 23:08:53 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-12-14 23:08:54 | INFO | train | {"epoch": 4, "train_loss": "2.341", "train_nll_loss": "0.092", "train_accuracy": "41.3", "train_wps": "2719.4", "train_ups": "3.33", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "1740", "train_lr": "7.85075e-06", "train_gnorm": "11.191", "train_train_wall": "58", "train_wall": "523"}
2022-12-14 23:08:54 | INFO | fairseq.trainer | begin training epoch 5
2022-12-14 23:09:02 | INFO | train_inner | {"epoch": 5, "update": 4.138, "loss": "2.231", "nll_loss": "0.087", "accuracy": "44.3", "wps": "948.6", "ups": "1.17", "wpb": "812.7", "bsz": "31.8", "num_updates": "1800", "lr": "7.76119e-06", "gnorm": "12.528", "train_wall": "13", "wall": "532"}
2022-12-14 23:09:16 | INFO | train_inner | {"epoch": 5, "update": 4.368, "loss": "2.163", "nll_loss": "0.085", "accuracy": "46.7", "wps": "5969.2", "ups": "7.31", "wpb": "817.1", "bsz": "32", "num_updates": "1900", "lr": "7.61194e-06", "gnorm": "14.446", "train_wall": "14", "wall": "546"}
2022-12-14 23:09:29 | INFO | train_inner | {"epoch": 5, "update": 4.598, "loss": "2.057", "nll_loss": "0.081", "accuracy": "49.5", "wps": "6123.6", "ups": "7.5", "wpb": "816.7", "bsz": "32", "num_updates": "2000", "lr": "7.46269e-06", "gnorm": "15.289", "train_wall": "13", "wall": "559"}
2022-12-14 23:09:43 | INFO | train_inner | {"epoch": 5, "update": 4.828, "loss": "2.066", "nll_loss": "0.081", "accuracy": "49.4", "wps": "6032.1", "ups": "7.39", "wpb": "815.8", "bsz": "32", "num_updates": "2100", "lr": "7.31343e-06", "gnorm": "16.779", "train_wall": "13", "wall": "573"}
2022-12-14 23:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:09:55 | INFO | valid | {"epoch": 5, "valid_loss": "1.994", "valid_nll_loss": "0.078", "valid_accuracy": "51.3", "valid_wps": "17983.1", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "2175", "valid_best_accuracy": "51.3"}
2022-12-14 23:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2175 updates
2022-12-14 23:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 5 @ 2175 updates, score 51.3) (writing took 68.95355760632083 seconds)
2022-12-14 23:11:04 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-12-14 23:11:05 | INFO | train | {"epoch": 5, "train_loss": "2.097", "train_nll_loss": "0.082", "train_accuracy": "48.6", "train_wps": "2730.7", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "2175", "train_lr": "7.20149e-06", "train_gnorm": "15.258", "train_train_wall": "58", "train_wall": "654"}
2022-12-14 23:11:05 | INFO | fairseq.trainer | begin training epoch 6
2022-12-14 23:11:08 | INFO | train_inner | {"epoch": 6, "update": 5.057, "loss": "1.98", "nll_loss": "0.078", "accuracy": "52.4", "wps": "950.6", "ups": "1.17", "wpb": "812.6", "bsz": "31.8", "num_updates": "2200", "lr": "7.16418e-06", "gnorm": "16.629", "train_wall": "13", "wall": "658"}
2022-12-14 23:11:22 | INFO | train_inner | {"epoch": 6, "update": 5.287, "loss": "1.878", "nll_loss": "0.074", "accuracy": "56", "wps": "6057.6", "ups": "7.41", "wpb": "817.5", "bsz": "32", "num_updates": "2300", "lr": "7.01493e-06", "gnorm": "16.456", "train_wall": "13", "wall": "672"}
2022-12-14 23:11:35 | INFO | train_inner | {"epoch": 6, "update": 5.517, "loss": "1.877", "nll_loss": "0.074", "accuracy": "54.8", "wps": "6258.7", "ups": "7.66", "wpb": "816.8", "bsz": "32", "num_updates": "2400", "lr": "6.86567e-06", "gnorm": "18.138", "train_wall": "13", "wall": "685"}
2022-12-14 23:11:48 | INFO | train_inner | {"epoch": 6, "update": 5.747, "loss": "1.853", "nll_loss": "0.073", "accuracy": "55.1", "wps": "5988.8", "ups": "7.34", "wpb": "816", "bsz": "32", "num_updates": "2500", "lr": "6.71642e-06", "gnorm": "22.544", "train_wall": "13", "wall": "698"}
2022-12-14 23:12:02 | INFO | train_inner | {"epoch": 6, "update": 5.977, "loss": "1.699", "nll_loss": "0.067", "accuracy": "60.2", "wps": "5902.6", "ups": "7.23", "wpb": "816.5", "bsz": "32", "num_updates": "2600", "lr": "6.56716e-06", "gnorm": "21.125", "train_wall": "14", "wall": "712"}
2022-12-14 23:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:12:06 | INFO | valid | {"epoch": 6, "valid_loss": "1.61", "valid_nll_loss": "0.063", "valid_accuracy": "61.7", "valid_wps": "17985.6", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "2610", "valid_best_accuracy": "61.7"}
2022-12-14 23:12:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2610 updates
2022-12-14 23:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:13:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 6 @ 2610 updates, score 61.7) (writing took 68.99348186794668 seconds)
2022-12-14 23:13:15 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-12-14 23:13:16 | INFO | train | {"epoch": 6, "train_loss": "1.825", "train_nll_loss": "0.072", "train_accuracy": "56.6", "train_wps": "2732.6", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "2610", "train_lr": "6.55224e-06", "train_gnorm": "19.414", "train_train_wall": "58", "train_wall": "785"}
2022-12-14 23:13:16 | INFO | fairseq.trainer | begin training epoch 7
2022-12-14 23:13:28 | INFO | train_inner | {"epoch": 7, "update": 6.207, "loss": "1.623", "nll_loss": "0.064", "accuracy": "62.5", "wps": "953.1", "ups": "1.17", "wpb": "812.8", "bsz": "31.8", "num_updates": "2700", "lr": "6.41791e-06", "gnorm": "22.972", "train_wall": "13", "wall": "797"}
2022-12-14 23:13:41 | INFO | train_inner | {"epoch": 7, "update": 6.437, "loss": "1.56", "nll_loss": "0.061", "accuracy": "64.2", "wps": "6035.9", "ups": "7.39", "wpb": "816.9", "bsz": "32", "num_updates": "2800", "lr": "6.26866e-06", "gnorm": "22.124", "train_wall": "13", "wall": "811"}
2022-12-14 23:13:55 | INFO | train_inner | {"epoch": 7, "update": 6.667, "loss": "1.481", "nll_loss": "0.058", "accuracy": "66.8", "wps": "6041.1", "ups": "7.4", "wpb": "816.1", "bsz": "32", "num_updates": "2900", "lr": "6.1194e-06", "gnorm": "23.723", "train_wall": "13", "wall": "825"}
2022-12-14 23:14:08 | INFO | train_inner | {"epoch": 7, "update": 6.897, "loss": "1.456", "nll_loss": "0.057", "accuracy": "66.7", "wps": "6051.7", "ups": "7.4", "wpb": "817.3", "bsz": "32", "num_updates": "3000", "lr": "5.97015e-06", "gnorm": "24.93", "train_wall": "13", "wall": "838"}
2022-12-14 23:14:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:14:16 | INFO | valid | {"epoch": 7, "valid_loss": "1.357", "valid_nll_loss": "0.053", "valid_accuracy": "66.5", "valid_wps": "17959", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3045", "valid_best_accuracy": "66.5"}
2022-12-14 23:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 3045 updates
2022-12-14 23:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 7 @ 3045 updates, score 66.5) (writing took 68.97202791692689 seconds)
2022-12-14 23:15:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-12-14 23:15:26 | INFO | train | {"epoch": 7, "train_loss": "1.511", "train_nll_loss": "0.059", "train_accuracy": "65.8", "train_wps": "2737.5", "train_ups": "3.36", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3045", "train_lr": "5.90299e-06", "train_gnorm": "23.274", "train_train_wall": "58", "train_wall": "915"}
2022-12-14 23:15:26 | INFO | fairseq.trainer | begin training epoch 8
2022-12-14 23:15:33 | INFO | train_inner | {"epoch": 8, "update": 7.126, "loss": "1.332", "nll_loss": "0.052", "accuracy": "71.4", "wps": "954", "ups": "1.17", "wpb": "812.6", "bsz": "31.8", "num_updates": "3100", "lr": "5.8209e-06", "gnorm": "22.357", "train_wall": "13", "wall": "923"}
2022-12-14 23:15:47 | INFO | train_inner | {"epoch": 8, "update": 7.356, "loss": "1.267", "nll_loss": "0.05", "accuracy": "73.7", "wps": "6072.5", "ups": "7.44", "wpb": "816.3", "bsz": "32", "num_updates": "3200", "lr": "5.67164e-06", "gnorm": "23.587", "train_wall": "13", "wall": "937"}
2022-12-14 23:16:01 | INFO | train_inner | {"epoch": 8, "update": 7.586, "loss": "1.247", "nll_loss": "0.049", "accuracy": "73.6", "wps": "5951.3", "ups": "7.28", "wpb": "817", "bsz": "32", "num_updates": "3300", "lr": "5.52239e-06", "gnorm": "22.889", "train_wall": "14", "wall": "951"}
2022-12-14 23:16:14 | INFO | train_inner | {"epoch": 8, "update": 7.816, "loss": "1.179", "nll_loss": "0.046", "accuracy": "75.7", "wps": "5976.8", "ups": "7.33", "wpb": "815.9", "bsz": "32", "num_updates": "3400", "lr": "5.37313e-06", "gnorm": "24.921", "train_wall": "14", "wall": "964"}
2022-12-14 23:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:16:27 | INFO | valid | {"epoch": 8, "valid_loss": "0.988", "valid_nll_loss": "0.039", "valid_accuracy": "81.9", "valid_wps": "17144.1", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3480", "valid_best_accuracy": "81.9"}
2022-12-14 23:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3480 updates
2022-12-14 23:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 8 @ 3480 updates, score 81.9) (writing took 68.99656857922673 seconds)
2022-12-14 23:17:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-12-14 23:17:37 | INFO | train | {"epoch": 8, "train_loss": "1.215", "train_nll_loss": "0.048", "train_accuracy": "74.6", "train_wps": "2728.5", "train_ups": "3.34", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3480", "train_lr": "5.25373e-06", "train_gnorm": "23.974", "train_train_wall": "58", "train_wall": "1046"}
2022-12-14 23:17:37 | INFO | fairseq.trainer | begin training epoch 9
2022-12-14 23:17:40 | INFO | train_inner | {"epoch": 9, "update": 8.046, "loss": "1.057", "nll_loss": "0.041", "accuracy": "78.9", "wps": "949.3", "ups": "1.17", "wpb": "812.8", "bsz": "31.8", "num_updates": "3500", "lr": "5.22388e-06", "gnorm": "24.865", "train_wall": "13", "wall": "1050"}
2022-12-14 23:17:53 | INFO | train_inner | {"epoch": 9, "update": 8.276, "loss": "1.027", "nll_loss": "0.04", "accuracy": "79.4", "wps": "6216.7", "ups": "7.61", "wpb": "817.3", "bsz": "32", "num_updates": "3600", "lr": "5.07463e-06", "gnorm": "24.272", "train_wall": "13", "wall": "1063"}
2022-12-14 23:18:07 | INFO | train_inner | {"epoch": 9, "update": 8.506, "loss": "1.002", "nll_loss": "0.039", "accuracy": "80.2", "wps": "6074.7", "ups": "7.44", "wpb": "816.7", "bsz": "32", "num_updates": "3700", "lr": "4.92537e-06", "gnorm": "25.486", "train_wall": "13", "wall": "1077"}
2022-12-14 23:18:21 | INFO | train_inner | {"epoch": 9, "update": 8.736, "loss": "0.915", "nll_loss": "0.036", "accuracy": "83.4", "wps": "5868.1", "ups": "7.19", "wpb": "816", "bsz": "32", "num_updates": "3800", "lr": "4.77612e-06", "gnorm": "22.159", "train_wall": "14", "wall": "1091"}
2022-12-14 23:18:35 | INFO | train_inner | {"epoch": 9, "update": 8.966, "loss": "0.891", "nll_loss": "0.035", "accuracy": "83.1", "wps": "5847.7", "ups": "7.16", "wpb": "817", "bsz": "32", "num_updates": "3900", "lr": "4.62687e-06", "gnorm": "22.461", "train_wall": "14", "wall": "1105"}
2022-12-14 23:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:18:39 | INFO | valid | {"epoch": 9, "valid_loss": "0.801", "valid_nll_loss": "0.031", "valid_accuracy": "84.7", "valid_wps": "17163.5", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3915", "valid_best_accuracy": "84.7"}
2022-12-14 23:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3915 updates
2022-12-14 23:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:19:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 9 @ 3915 updates, score 84.7) (writing took 68.98874272499233 seconds)
2022-12-14 23:19:48 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-12-14 23:19:49 | INFO | train | {"epoch": 9, "train_loss": "0.955", "train_nll_loss": "0.037", "train_accuracy": "81.7", "train_wps": "2713.1", "train_ups": "3.33", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3915", "train_lr": "4.60448e-06", "train_gnorm": "23.612", "train_train_wall": "59", "train_wall": "1178"}
2022-12-14 23:19:49 | INFO | fairseq.trainer | begin training epoch 10
2022-12-14 23:20:01 | INFO | train_inner | {"epoch": 10, "update": 9.195, "loss": "0.802", "nll_loss": "0.031", "accuracy": "86.9", "wps": "945.7", "ups": "1.16", "wpb": "812.6", "bsz": "31.8", "num_updates": "4000", "lr": "4.47761e-06", "gnorm": "22.227", "train_wall": "14", "wall": "1190"}
2022-12-14 23:20:14 | INFO | train_inner | {"epoch": 10, "update": 9.425, "loss": "0.786", "nll_loss": "0.031", "accuracy": "85.4", "wps": "6156.2", "ups": "7.53", "wpb": "817.3", "bsz": "32", "num_updates": "4100", "lr": "4.32836e-06", "gnorm": "21.26", "train_wall": "13", "wall": "1204"}
2022-12-14 23:20:27 | INFO | train_inner | {"epoch": 10, "update": 9.655, "loss": "0.742", "nll_loss": "0.029", "accuracy": "87.2", "wps": "6102.7", "ups": "7.47", "wpb": "817.2", "bsz": "32", "num_updates": "4200", "lr": "4.1791e-06", "gnorm": "21.768", "train_wall": "13", "wall": "1217"}
2022-12-14 23:20:41 | INFO | train_inner | {"epoch": 10, "update": 9.885, "loss": "0.696", "nll_loss": "0.027", "accuracy": "88.7", "wps": "6009.3", "ups": "7.36", "wpb": "816.4", "bsz": "32", "num_updates": "4300", "lr": "4.02985e-06", "gnorm": "19.644", "train_wall": "13", "wall": "1231"}
2022-12-14 23:20:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:20:50 | INFO | valid | {"epoch": 10, "valid_loss": "0.6", "valid_nll_loss": "0.024", "valid_accuracy": "89.8", "valid_wps": "17940.3", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "4350", "valid_best_accuracy": "89.8"}
2022-12-14 23:20:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4350 updates
2022-12-14 23:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 10 @ 4350 updates, score 89.8) (writing took 68.97391041601077 seconds)
2022-12-14 23:21:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-12-14 23:22:00 | INFO | train | {"epoch": 10, "train_loss": "0.745", "train_nll_loss": "0.029", "train_accuracy": "87.2", "train_wps": "2729.1", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "4350", "train_lr": "3.95522e-06", "train_gnorm": "21.182", "train_train_wall": "58", "train_wall": "1309"}
2022-12-14 23:22:00 | INFO | fairseq.trainer | begin training epoch 11
2022-12-14 23:22:07 | INFO | train_inner | {"epoch": 11, "update": 10.115, "loss": "0.683", "nll_loss": "0.027", "accuracy": "88.5", "wps": "946.2", "ups": "1.16", "wpb": "812.3", "bsz": "31.8", "num_updates": "4400", "lr": "3.8806e-06", "gnorm": "20.186", "train_wall": "14", "wall": "1317"}
2022-12-14 23:22:20 | INFO | train_inner | {"epoch": 11, "update": 10.345, "loss": "0.625", "nll_loss": "0.024", "accuracy": "90.5", "wps": "6022", "ups": "7.37", "wpb": "816.9", "bsz": "32", "num_updates": "4500", "lr": "3.73134e-06", "gnorm": "18.863", "train_wall": "13", "wall": "1330"}
2022-12-14 23:22:34 | INFO | train_inner | {"epoch": 11, "update": 10.575, "loss": "0.576", "nll_loss": "0.023", "accuracy": "91.5", "wps": "6274.6", "ups": "7.68", "wpb": "817.2", "bsz": "32", "num_updates": "4600", "lr": "3.58209e-06", "gnorm": "20.098", "train_wall": "13", "wall": "1343"}
2022-12-14 23:22:47 | INFO | train_inner | {"epoch": 11, "update": 10.805, "loss": "0.58", "nll_loss": "0.023", "accuracy": "90.7", "wps": "6198.2", "ups": "7.59", "wpb": "816.8", "bsz": "32", "num_updates": "4700", "lr": "3.43284e-06", "gnorm": "19.932", "train_wall": "13", "wall": "1357"}
2022-12-14 23:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:23:01 | INFO | valid | {"epoch": 11, "valid_loss": "0.455", "valid_nll_loss": "0.018", "valid_accuracy": "93", "valid_wps": "18017.1", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "4785", "valid_best_accuracy": "93"}
2022-12-14 23:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4785 updates
2022-12-14 23:23:24 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 11 @ 4785 updates, score 93.0) (writing took 68.95930678909644 seconds)
2022-12-14 23:24:10 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-12-14 23:24:11 | INFO | train | {"epoch": 11, "train_loss": "0.599", "train_nll_loss": "0.023", "train_accuracy": "90.6", "train_wps": "2735.1", "train_ups": "3.35", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "4785", "train_lr": "3.30597e-06", "train_gnorm": "19.684", "train_train_wall": "58", "train_wall": "1440"}
2022-12-14 23:24:11 | INFO | fairseq.trainer | begin training epoch 12
2022-12-14 23:24:13 | INFO | train_inner | {"epoch": 12, "update": 11.034, "loss": "0.564", "nll_loss": "0.022", "accuracy": "91", "wps": "943", "ups": "1.16", "wpb": "811.6", "bsz": "31.8", "num_updates": "4800", "lr": "3.28358e-06", "gnorm": "20.212", "train_wall": "14", "wall": "1443"}
2022-12-14 23:24:26 | INFO | train_inner | {"epoch": 12, "update": 11.264, "loss": "0.535", "nll_loss": "0.021", "accuracy": "91.7", "wps": "6058", "ups": "7.42", "wpb": "816.6", "bsz": "32", "num_updates": "4900", "lr": "3.13433e-06", "gnorm": "18.145", "train_wall": "13", "wall": "1456"}
2022-12-14 23:25:22 | INFO | train_inner | {"epoch": 12, "update": 11.494, "loss": "0.515", "nll_loss": "0.02", "accuracy": "91.7", "wps": "6098", "ups": "7.46", "wpb": "817", "bsz": "32", "num_updates": "5000", "lr": "2.98507e-06", "gnorm": "18.987", "train_wall": "13", "wall": "1470"}
2022-12-14 23:25:35 | INFO | train_inner | {"epoch": 12, "update": 11.724, "loss": "0.462", "nll_loss": "0.018", "accuracy": "93.4", "wps": "5970.4", "ups": "7.32", "wpb": "816.2", "bsz": "32", "num_updates": "5100", "lr": "2.83582e-06", "gnorm": "15.764", "train_wall": "14", "wall": "1525"}
2022-12-14 23:25:48 | INFO | train_inner | {"epoch": 12, "update": 11.954, "loss": "0.453", "nll_loss": "0.018", "accuracy": "93.5", "wps": "6187.4", "ups": "7.57", "wpb": "817.2", "bsz": "32", "num_updates": "5200", "lr": "2.68657e-06", "gnorm": "16.244", "train_wall": "13", "wall": "1538"}
2022-12-14 23:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:25:53 | INFO | valid | {"epoch": 12, "valid_loss": "0.371", "valid_nll_loss": "0.015", "valid_accuracy": "94.8", "valid_wps": "18012.1", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "5220", "valid_best_accuracy": "94.8"}
2022-12-14 23:25:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 5220 updates
2022-12-14 23:25:56 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 12 @ 5220 updates, score 94.8) (writing took 8.509807634633034 seconds)
2022-12-14 23:26:02 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-12-14 23:26:03 | INFO | train | {"epoch": 12, "train_loss": "0.491", "train_nll_loss": "0.019", "train_accuracy": "92.6", "train_wps": "3192.4", "train_ups": "3.91", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "5220", "train_lr": "2.65672e-06", "train_gnorm": "17.309", "train_train_wall": "58", "train_wall": "1552"}
2022-12-14 23:26:03 | INFO | fairseq.trainer | begin training epoch 13
2022-12-14 23:26:13 | INFO | train_inner | {"epoch": 13, "update": 12.184, "loss": "0.45", "nll_loss": "0.018", "accuracy": "92.9", "wps": "3259", "ups": "4.01", "wpb": "811.9", "bsz": "31.8", "num_updates": "5300", "lr": "2.53731e-06", "gnorm": "16.968", "train_wall": "13", "wall": "1563"}
2022-12-14 23:26:27 | INFO | train_inner | {"epoch": 13, "update": 12.414, "loss": "0.414", "nll_loss": "0.016", "accuracy": "94", "wps": "5973.4", "ups": "7.31", "wpb": "817.2", "bsz": "32", "num_updates": "5400", "lr": "2.38806e-06", "gnorm": "16.703", "train_wall": "14", "wall": "1577"}
2022-12-14 23:26:41 | INFO | train_inner | {"epoch": 13, "update": 12.644, "loss": "0.42", "nll_loss": "0.016", "accuracy": "93.6", "wps": "6105.7", "ups": "7.47", "wpb": "817.9", "bsz": "32", "num_updates": "5500", "lr": "2.23881e-06", "gnorm": "17.576", "train_wall": "13", "wall": "1590"}
2022-12-14 23:26:54 | INFO | train_inner | {"epoch": 13, "update": 12.874, "loss": "0.392", "nll_loss": "0.015", "accuracy": "94.5", "wps": "6186.8", "ups": "7.58", "wpb": "816.5", "bsz": "32", "num_updates": "5600", "lr": "2.08955e-06", "gnorm": "15.539", "train_wall": "13", "wall": "1604"}
2022-12-14 23:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:27:04 | INFO | valid | {"epoch": 13, "valid_loss": "0.324", "valid_nll_loss": "0.013", "valid_accuracy": "96.1", "valid_wps": "17747", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "5655", "valid_best_accuracy": "96.1"}
2022-12-14 23:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5655 updates
2022-12-14 23:27:07 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:27:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 13 @ 5655 updates, score 96.1) (writing took 8.47767718276009 seconds)
2022-12-14 23:27:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-12-14 23:27:13 | INFO | train | {"epoch": 13, "train_loss": "0.412", "train_nll_loss": "0.016", "train_accuracy": "93.9", "train_wps": "5114.9", "train_ups": "6.27", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "5655", "train_lr": "2.00746e-06", "train_gnorm": "16.38", "train_train_wall": "58", "train_wall": "1622"}
2022-12-14 23:27:13 | INFO | fairseq.trainer | begin training epoch 14
2022-12-14 23:27:19 | INFO | train_inner | {"epoch": 14, "update": 13.103, "loss": "0.386", "nll_loss": "0.015", "accuracy": "94.7", "wps": "3209.7", "ups": "3.96", "wpb": "811.5", "bsz": "31.8", "num_updates": "5700", "lr": "1.9403e-06", "gnorm": "15.063", "train_wall": "13", "wall": "1629"}
2022-12-14 23:27:33 | INFO | train_inner | {"epoch": 14, "update": 13.333, "loss": "0.353", "nll_loss": "0.014", "accuracy": "95.5", "wps": "5998.9", "ups": "7.34", "wpb": "817.4", "bsz": "32", "num_updates": "5800", "lr": "1.79104e-06", "gnorm": "14.38", "train_wall": "13", "wall": "1643"}
2022-12-14 23:27:46 | INFO | train_inner | {"epoch": 14, "update": 13.563, "loss": "0.343", "nll_loss": "0.013", "accuracy": "95.6", "wps": "6041.8", "ups": "7.4", "wpb": "816.2", "bsz": "32", "num_updates": "5900", "lr": "1.64179e-06", "gnorm": "14.487", "train_wall": "13", "wall": "1656"}
2022-12-14 23:28:00 | INFO | train_inner | {"epoch": 14, "update": 13.793, "loss": "0.362", "nll_loss": "0.014", "accuracy": "95.2", "wps": "6167.4", "ups": "7.54", "wpb": "817.5", "bsz": "32", "num_updates": "6000", "lr": "1.49254e-06", "gnorm": "15.559", "train_wall": "13", "wall": "1669"}
2022-12-14 23:28:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:28:14 | INFO | valid | {"epoch": 14, "valid_loss": "0.296", "valid_nll_loss": "0.012", "valid_accuracy": "96.3", "valid_wps": "17834.4", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6090", "valid_best_accuracy": "96.3"}
2022-12-14 23:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 6090 updates
2022-12-14 23:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 14 @ 6090 updates, score 96.3) (writing took 8.421812950167805 seconds)
2022-12-14 23:28:23 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-12-14 23:28:24 | INFO | train | {"epoch": 14, "train_loss": "0.352", "train_nll_loss": "0.014", "train_accuracy": "95.4", "train_wps": "5101.4", "train_ups": "6.25", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6090", "train_lr": "1.35821e-06", "train_gnorm": "14.891", "train_train_wall": "58", "train_wall": "1693"}
2022-12-14 23:28:24 | INFO | fairseq.trainer | begin training epoch 15
2022-12-14 23:28:25 | INFO | train_inner | {"epoch": 15, "update": 14.023, "loss": "0.332", "nll_loss": "0.013", "accuracy": "96", "wps": "3198.8", "ups": "3.94", "wpb": "812.2", "bsz": "31.8", "num_updates": "6100", "lr": "1.34328e-06", "gnorm": "14.48", "train_wall": "14", "wall": "1695"}
2022-12-14 23:28:39 | INFO | train_inner | {"epoch": 15, "update": 14.253, "loss": "0.321", "nll_loss": "0.013", "accuracy": "95.9", "wps": "6082.4", "ups": "7.45", "wpb": "817", "bsz": "32", "num_updates": "6200", "lr": "1.19403e-06", "gnorm": "13.887", "train_wall": "13", "wall": "1708"}
2022-12-14 23:28:52 | INFO | train_inner | {"epoch": 15, "update": 14.483, "loss": "0.313", "nll_loss": "0.012", "accuracy": "96.1", "wps": "6025.7", "ups": "7.38", "wpb": "816", "bsz": "32", "num_updates": "6300", "lr": "1.04478e-06", "gnorm": "13.892", "train_wall": "13", "wall": "1722"}
2022-12-14 23:29:06 | INFO | train_inner | {"epoch": 15, "update": 14.713, "loss": "0.308", "nll_loss": "0.012", "accuracy": "96.4", "wps": "6046.1", "ups": "7.4", "wpb": "817.5", "bsz": "32", "num_updates": "6400", "lr": "8.95522e-07", "gnorm": "14.03", "train_wall": "13", "wall": "1736"}
2022-12-14 23:29:19 | INFO | train_inner | {"epoch": 15, "update": 14.943, "loss": "0.311", "nll_loss": "0.012", "accuracy": "95.7", "wps": "6124.1", "ups": "7.5", "wpb": "816.1", "bsz": "32", "num_updates": "6500", "lr": "7.46269e-07", "gnorm": "14.013", "train_wall": "13", "wall": "1749"}
2022-12-14 23:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:29:25 | INFO | valid | {"epoch": 15, "valid_loss": "0.261", "valid_nll_loss": "0.01", "valid_accuracy": "96.8", "valid_wps": "17875.1", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6525", "valid_best_accuracy": "96.8"}
2022-12-14 23:29:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6525 updates
2022-12-14 23:29:28 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 15 @ 6525 updates, score 96.8) (writing took 8.44085046928376 seconds)
2022-12-14 23:29:33 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-12-14 23:29:34 | INFO | train | {"epoch": 15, "train_loss": "0.314", "train_nll_loss": "0.012", "train_accuracy": "96", "train_wps": "5106.9", "train_ups": "6.26", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6525", "train_lr": "7.08955e-07", "train_gnorm": "13.888", "train_train_wall": "58", "train_wall": "1763"}
2022-12-14 23:29:34 | INFO | fairseq.trainer | begin training epoch 16
2022-12-14 23:29:44 | INFO | train_inner | {"epoch": 16, "update": 15.172, "loss": "0.303", "nll_loss": "0.012", "accuracy": "96.3", "wps": "3240.9", "ups": "3.99", "wpb": "812.6", "bsz": "31.8", "num_updates": "6600", "lr": "5.97015e-07", "gnorm": "13.542", "train_wall": "13", "wall": "1774"}
2022-12-14 23:29:58 | INFO | train_inner | {"epoch": 16, "update": 15.402, "loss": "0.292", "nll_loss": "0.011", "accuracy": "96.5", "wps": "6094.5", "ups": "7.47", "wpb": "816.4", "bsz": "32", "num_updates": "6700", "lr": "4.47761e-07", "gnorm": "13.173", "train_wall": "13", "wall": "1787"}
2022-12-14 23:30:11 | INFO | train_inner | {"epoch": 16, "update": 15.632, "loss": "0.285", "nll_loss": "0.011", "accuracy": "96.7", "wps": "6031.5", "ups": "7.38", "wpb": "816.8", "bsz": "32", "num_updates": "6800", "lr": "2.98507e-07", "gnorm": "12.714", "train_wall": "13", "wall": "1801"}
2022-12-14 23:30:25 | INFO | train_inner | {"epoch": 16, "update": 15.862, "loss": "0.282", "nll_loss": "0.011", "accuracy": "96.8", "wps": "5992.1", "ups": "7.33", "wpb": "817", "bsz": "32", "num_updates": "6900", "lr": "1.49254e-07", "gnorm": "12.913", "train_wall": "13", "wall": "1815"}
2022-12-14 23:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:30:35 | INFO | valid | {"epoch": 16, "valid_loss": "0.251", "valid_nll_loss": "0.01", "valid_accuracy": "97", "valid_wps": "17888.7", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6960", "valid_best_accuracy": "97"}
2022-12-14 23:30:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6960 updates
2022-12-14 23:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 16 @ 6960 updates, score 97.0) (writing took 10.166342440992594 seconds)
2022-12-14 23:30:45 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-12-14 23:30:46 | INFO | train | {"epoch": 16, "train_loss": "0.29", "train_nll_loss": "0.011", "train_accuracy": "96.6", "train_wps": "4981.1", "train_ups": "6.11", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6960", "train_lr": "5.97015e-08", "train_gnorm": "13.091", "train_train_wall": "58", "train_wall": "1835"}
2022-12-14 23:30:46 | INFO | fairseq.trainer | begin training epoch 17
2022-12-14 23:30:52 | INFO | train_inner | {"epoch": 17, "update": 16.092, "loss": "0.296", "nll_loss": "0.012", "accuracy": "96.5", "wps": "3029.2", "ups": "3.73", "wpb": "813.1", "bsz": "31.8", "num_updates": "7000", "lr": "0", "gnorm": "12.283", "train_wall": "13", "wall": "1842"}
2022-12-14 23:30:52 | INFO | fairseq_cli.train | Stopping training due to num_updates: 7000 >= max_update: 7000
2022-12-14 23:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:30:54 | INFO | valid | {"epoch": 17, "valid_loss": "0.251", "valid_nll_loss": "0.01", "valid_accuracy": "97", "valid_wps": "17979.2", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "7000", "valid_best_accuracy": "97"}
2022-12-14 23:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 7000 updates
2022-12-14 23:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt
2022-12-14 23:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-5_small_tmp.pt.pt (epoch 17 @ 7000 updates, score 97.0) (writing took 10.604009243659675 seconds)
2022-12-14 23:31:05 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-12-14 23:31:05 | INFO | train | {"epoch": 17, "train_loss": "0.291", "train_nll_loss": "0.011", "train_accuracy": "96.7", "train_wps": "1788.9", "train_ups": "2.19", "train_wpb": "817.2", "train_bsz": "32", "train_num_updates": "7000", "train_lr": "0", "train_gnorm": "11.622", "train_train_wall": "5", "train_wall": "1854"}
2022-12-14 23:31:05 | INFO | fairseq_cli.train | done training in 1855.1 seconds
disable_cp = False
mask_strategy = ['bar']
convert_encoding = OCTMIDI
crop_length = None
2022-12-14 23:31:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'tensorboard_logdir': 'checkpoints/board_apex_M2P_1e-6_small_tmp', 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': 'musicbert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': 4, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 7000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [1e-06], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoints/checkpoint_last_musicbert_small.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '_xai_apex_M2P_1e-6_small_tmp.pt', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='musicbert_small', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-6_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[1e-06], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-6_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'task': Namespace(_name='xai', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-6_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[1e-06], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-6_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'criterion': Namespace(_name='M2P_xai', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adv=False, all_gather_list_size=16384, arch='musicbert_small', attention_dropout=0.1, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_xai_apex_M2P_1e-6_small_tmp.pt', classification_head_name='xai_head', clip_norm=0.0, cpu=False, criterion='M2P_xai', curriculum=0, data='processed/xai_data_bin_apex_reg_cls_augmented/0', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[1e-06], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=8192, max_tokens=32768, max_tokens_valid=32768, max_update=7000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_cls_classes=13, num_reg_classes=-1, num_shards=1, num_workers=0, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoints/checkpoint_last_musicbert_small.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=7, sentence_avg=False, separator_token=2, shard_id=0, shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, spectral_norm_regression_head=False, stop_min_lr=-1.0, stop_time_hours=0, task='xai', tensorboard_logdir='checkpoints/board_apex_M2P_1e-6_small_tmp', threshold_loss_scale=None, tokenizer=None, total_num_update='7000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[8], use_bmuf=False, use_old_adam=False, user_dir='musicbert', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=300, weight_decay=0.01, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [1e-06]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 300, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 7000.0, 'lr': [1e-06]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}
2022-12-14 23:31:15 | INFO | musicbert | [input] dictionary: 1237 types
2022-12-14 23:31:15 | INFO | musicbert | [label] dictionary: 497 types
2022-12-14 23:31:15 | INFO | fairseq.data.data_utils | loaded 1,545 examples from: processed/xai_data_bin_apex_reg_cls_augmented/0/input0/valid
dataset: 1545
labels: 1545
2022-12-14 23:31:15 | INFO | fairseq_cli.train | MusicBERTModel(
  (encoder): MusicBERTEncoder(
    (sentence_encoder): OctupleEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(1237, 512, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(8194, 512, padding_idx=1)
      (emb_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerSentenceEncoderLayer(
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (downsampling): Sequential(
        (0): Linear(in_features=4096, out_features=512, bias=True)
      )
      (upsampling): Sequential(
        (0): Linear(in_features=512, out_features=4096, bias=True)
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=512, out_features=512, bias=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict(
    (xai_head): RobertaClassificationHead(
      (dense): Linear(in_features=512, out_features=512, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (out_proj): Linear(in_features=512, out_features=13, bias=True)
    )
  )
  (regression_heads): ModuleDict()
)
2022-12-14 23:31:15 | INFO | fairseq_cli.train | task: MusicBERTSentencePredictionMultilabelTaskXAI
2022-12-14 23:31:15 | INFO | fairseq_cli.train | model: MusicBERTModel
2022-12-14 23:31:15 | INFO | fairseq_cli.train | criterion: MusicBERTM2PCriterionForXAI
2022-12-14 23:31:15 | INFO | fairseq_cli.train | num. model params: 22,805,730 (num. trained: 22,805,730)
2022-12-14 23:31:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-12-14 23:31:16 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 7.927 GB ; name = NVIDIA GeForce GTX 1080                 
2022-12-14 23:31:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-12-14 23:31:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-12-14 23:31:16 | INFO | fairseq_cli.train | max tokens per GPU = 32768 and batch size per GPU = 4
2022-12-14 23:31:16 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last_musicbert_small.pt
2022-12-14 23:31:16 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last_musicbert_small.pt
2022-12-14 23:31:16 | INFO | fairseq.trainer | loading train data for epoch 1
2022-12-14 23:31:16 | INFO | fairseq.data.data_utils | loaded 13,903 examples from: processed/xai_data_bin_apex_reg_cls_augmented/0/input0/train
dataset: 13903
labels: 13903
2022-12-14 23:31:16 | INFO | fairseq.trainer | begin training epoch 1
2022-12-14 23:31:31 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "3.713", "nll_loss": "0.146", "accuracy": "8.7", "wps": "5909", "ups": "7.24", "wpb": "815.9", "bsz": "32", "num_updates": "100", "lr": "3.33333e-07", "gnorm": "3.32", "train_wall": "14", "wall": "14"}
2022-12-14 23:31:44 | INFO | train_inner | {"epoch": 1, "update": 0.46, "loss": "3.69", "nll_loss": "0.145", "accuracy": "8.2", "wps": "6136.3", "ups": "7.51", "wpb": "817.1", "bsz": "32", "num_updates": "200", "lr": "6.66667e-07", "gnorm": "3.099", "train_wall": "13", "wall": "28"}
2022-12-14 23:31:58 | INFO | train_inner | {"epoch": 1, "update": 0.69, "loss": "3.666", "nll_loss": "0.144", "accuracy": "9.1", "wps": "5966.5", "ups": "7.31", "wpb": "816.4", "bsz": "32", "num_updates": "300", "lr": "1e-06", "gnorm": "3.101", "train_wall": "14", "wall": "41"}
2022-12-14 23:32:12 | INFO | train_inner | {"epoch": 1, "update": 0.92, "loss": "3.634", "nll_loss": "0.142", "accuracy": "15.1", "wps": "5535", "ups": "6.77", "wpb": "817", "bsz": "32", "num_updates": "400", "lr": "9.85075e-07", "gnorm": "3.114", "train_wall": "15", "wall": "56"}
2022-12-14 23:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:32:20 | INFO | valid | {"epoch": 1, "valid_loss": "3.6", "valid_nll_loss": "0.141", "valid_accuracy": "22", "valid_wps": "17931.6", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "435"}
2022-12-14 23:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 435 updates
2022-12-14 23:32:22 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:32:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 1 @ 435 updates, score 22.0) (writing took 8.270816517062485 seconds)
2022-12-14 23:32:28 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-12-14 23:32:28 | INFO | train | {"epoch": 1, "train_loss": "3.669", "train_nll_loss": "0.144", "train_accuracy": "11.1", "train_wps": "4994.8", "train_ups": "6.12", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "435", "train_lr": "9.79851e-07", "train_gnorm": "3.157", "train_train_wall": "60", "train_wall": "72"}
2022-12-14 23:32:28 | INFO | fairseq.trainer | begin training epoch 2
2022-12-14 23:32:36 | INFO | train_inner | {"epoch": 2, "update": 1.149, "loss": "3.594", "nll_loss": "0.141", "accuracy": "21.2", "wps": "3386.4", "ups": "4.17", "wpb": "812.8", "bsz": "31.8", "num_updates": "500", "lr": "9.70149e-07", "gnorm": "3.153", "train_wall": "13", "wall": "80"}
2022-12-14 23:32:50 | INFO | train_inner | {"epoch": 2, "update": 1.379, "loss": "3.569", "nll_loss": "0.14", "accuracy": "19.9", "wps": "5898.4", "ups": "7.23", "wpb": "815.4", "bsz": "32", "num_updates": "600", "lr": "9.55224e-07", "gnorm": "3.237", "train_wall": "14", "wall": "94"}
2022-12-14 23:33:04 | INFO | train_inner | {"epoch": 2, "update": 1.609, "loss": "3.513", "nll_loss": "0.138", "accuracy": "22.5", "wps": "6101.8", "ups": "7.47", "wpb": "817.1", "bsz": "32", "num_updates": "700", "lr": "9.40299e-07", "gnorm": "3.216", "train_wall": "13", "wall": "107"}
2022-12-14 23:33:18 | INFO | train_inner | {"epoch": 2, "update": 1.839, "loss": "3.488", "nll_loss": "0.137", "accuracy": "22.9", "wps": "5834.3", "ups": "7.13", "wpb": "817.8", "bsz": "32", "num_updates": "800", "lr": "9.25373e-07", "gnorm": "3.325", "train_wall": "14", "wall": "122"}
2022-12-14 23:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:33:30 | INFO | valid | {"epoch": 2, "valid_loss": "3.391", "valid_nll_loss": "0.133", "valid_accuracy": "22.2", "valid_wps": "17923", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "870", "valid_best_accuracy": "22.2"}
2022-12-14 23:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 870 updates
2022-12-14 23:33:33 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:33:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 2 @ 870 updates, score 22.2) (writing took 8.376699318177998 seconds)
2022-12-14 23:33:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-12-14 23:33:39 | INFO | train | {"epoch": 2, "train_loss": "3.519", "train_nll_loss": "0.138", "train_accuracy": "22.3", "train_wps": "5056.5", "train_ups": "6.2", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "870", "train_lr": "9.14925e-07", "train_gnorm": "3.27", "train_train_wall": "59", "train_wall": "142"}
2022-12-14 23:33:39 | INFO | fairseq.trainer | begin training epoch 3
2022-12-14 23:33:43 | INFO | train_inner | {"epoch": 3, "update": 2.069, "loss": "3.421", "nll_loss": "0.134", "accuracy": "25.3", "wps": "3236.8", "ups": "3.99", "wpb": "812.1", "bsz": "31.8", "num_updates": "900", "lr": "9.10448e-07", "gnorm": "3.42", "train_wall": "13", "wall": "147"}
2022-12-14 23:33:57 | INFO | train_inner | {"epoch": 3, "update": 2.299, "loss": "3.355", "nll_loss": "0.131", "accuracy": "24.2", "wps": "5922.5", "ups": "7.25", "wpb": "817.4", "bsz": "32", "num_updates": "1000", "lr": "8.95522e-07", "gnorm": "3.521", "train_wall": "14", "wall": "160"}
2022-12-14 23:34:10 | INFO | train_inner | {"epoch": 3, "update": 2.529, "loss": "3.255", "nll_loss": "0.127", "accuracy": "25.6", "wps": "6041.9", "ups": "7.39", "wpb": "817.7", "bsz": "32", "num_updates": "1100", "lr": "8.80597e-07", "gnorm": "3.406", "train_wall": "13", "wall": "174"}
2022-12-14 23:34:24 | INFO | train_inner | {"epoch": 3, "update": 2.759, "loss": "3.203", "nll_loss": "0.126", "accuracy": "24.8", "wps": "5849.5", "ups": "7.17", "wpb": "816.2", "bsz": "32", "num_updates": "1200", "lr": "8.65672e-07", "gnorm": "3.384", "train_wall": "14", "wall": "188"}
2022-12-14 23:34:38 | INFO | train_inner | {"epoch": 3, "update": 2.989, "loss": "3.152", "nll_loss": "0.124", "accuracy": "24.9", "wps": "6015.6", "ups": "7.37", "wpb": "816.3", "bsz": "32", "num_updates": "1300", "lr": "8.50746e-07", "gnorm": "3.338", "train_wall": "13", "wall": "202"}
2022-12-14 23:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:34:41 | INFO | valid | {"epoch": 3, "valid_loss": "3.13", "valid_nll_loss": "0.123", "valid_accuracy": "22.5", "valid_wps": "17932.4", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "1305", "valid_best_accuracy": "22.5"}
2022-12-14 23:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1305 updates
2022-12-14 23:34:44 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:34:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 3 @ 1305 updates, score 22.5) (writing took 8.821659904904664 seconds)
2022-12-14 23:34:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-12-14 23:34:51 | INFO | train | {"epoch": 3, "train_loss": "3.253", "train_nll_loss": "0.127", "train_accuracy": "24.8", "train_wps": "5013.6", "train_ups": "6.15", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "1305", "train_lr": "8.5e-07", "train_gnorm": "3.418", "train_train_wall": "59", "train_wall": "213"}
2022-12-14 23:34:51 | INFO | fairseq.trainer | begin training epoch 4
2022-12-14 23:35:04 | INFO | train_inner | {"epoch": 4, "update": 3.218, "loss": "3.13", "nll_loss": "0.123", "accuracy": "24.4", "wps": "3141.3", "ups": "3.87", "wpb": "811.5", "bsz": "31.8", "num_updates": "1400", "lr": "8.35821e-07", "gnorm": "3.375", "train_wall": "14", "wall": "228"}
2022-12-14 23:35:17 | INFO | train_inner | {"epoch": 4, "update": 3.448, "loss": "3.072", "nll_loss": "0.12", "accuracy": "25.3", "wps": "6089", "ups": "7.46", "wpb": "816.1", "bsz": "32", "num_updates": "1500", "lr": "8.20896e-07", "gnorm": "3.314", "train_wall": "13", "wall": "241"}
2022-12-14 23:35:31 | INFO | train_inner | {"epoch": 4, "update": 3.678, "loss": "3.06", "nll_loss": "0.12", "accuracy": "26.2", "wps": "6035.3", "ups": "7.38", "wpb": "817.8", "bsz": "32", "num_updates": "1600", "lr": "8.0597e-07", "gnorm": "3.24", "train_wall": "13", "wall": "255"}
2022-12-14 23:35:45 | INFO | train_inner | {"epoch": 4, "update": 3.908, "loss": "3.027", "nll_loss": "0.118", "accuracy": "25.4", "wps": "5865.3", "ups": "7.17", "wpb": "817.8", "bsz": "32", "num_updates": "1700", "lr": "7.91045e-07", "gnorm": "3.098", "train_wall": "14", "wall": "269"}
2022-12-14 23:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:35:53 | INFO | valid | {"epoch": 4, "valid_loss": "3.026", "valid_nll_loss": "0.119", "valid_accuracy": "26.1", "valid_wps": "17911.5", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "1740", "valid_best_accuracy": "26.1"}
2022-12-14 23:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1740 updates
2022-12-14 23:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:36:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 4 @ 1740 updates, score 26.1) (writing took 8.475051779765636 seconds)
2022-12-14 23:36:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-12-14 23:36:02 | INFO | train | {"epoch": 4, "train_loss": "3.067", "train_nll_loss": "0.12", "train_accuracy": "25.4", "train_wps": "5042.4", "train_ups": "6.18", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "1740", "train_lr": "7.85075e-07", "train_gnorm": "3.242", "train_train_wall": "59", "train_wall": "285"}
2022-12-14 23:36:02 | INFO | fairseq.trainer | begin training epoch 5
2022-12-14 23:36:10 | INFO | train_inner | {"epoch": 5, "update": 4.138, "loss": "3.039", "nll_loss": "0.119", "accuracy": "25.3", "wps": "3219.4", "ups": "3.96", "wpb": "812.7", "bsz": "31.8", "num_updates": "1800", "lr": "7.76119e-07", "gnorm": "3.156", "train_wall": "13", "wall": "294"}
2022-12-14 23:36:24 | INFO | train_inner | {"epoch": 5, "update": 4.368, "loss": "3.02", "nll_loss": "0.118", "accuracy": "24.3", "wps": "5847.2", "ups": "7.16", "wpb": "817.1", "bsz": "32", "num_updates": "1900", "lr": "7.61194e-07", "gnorm": "3.197", "train_wall": "14", "wall": "308"}
2022-12-14 23:36:38 | INFO | train_inner | {"epoch": 5, "update": 4.598, "loss": "2.956", "nll_loss": "0.116", "accuracy": "25.9", "wps": "6067.8", "ups": "7.43", "wpb": "816.7", "bsz": "32", "num_updates": "2000", "lr": "7.46269e-07", "gnorm": "2.856", "train_wall": "13", "wall": "321"}
2022-12-14 23:36:51 | INFO | train_inner | {"epoch": 5, "update": 4.828, "loss": "2.961", "nll_loss": "0.116", "accuracy": "25.5", "wps": "5940.5", "ups": "7.28", "wpb": "815.8", "bsz": "32", "num_updates": "2100", "lr": "7.31343e-07", "gnorm": "2.991", "train_wall": "14", "wall": "335"}
2022-12-14 23:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:37:04 | INFO | valid | {"epoch": 5, "valid_loss": "2.971", "valid_nll_loss": "0.117", "valid_accuracy": "25.3", "valid_wps": "17918.4", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "2175", "valid_best_accuracy": "26.1"}
2022-12-14 23:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2175 updates
2022-12-14 23:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 5 @ 2175 updates, score 25.3) (writing took 2.991757307667285 seconds)
2022-12-14 23:37:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-12-14 23:37:08 | INFO | train | {"epoch": 5, "train_loss": "2.982", "train_nll_loss": "0.117", "train_accuracy": "25.5", "train_wps": "5463.1", "train_ups": "6.7", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "2175", "train_lr": "7.20149e-07", "train_gnorm": "3.031", "train_train_wall": "59", "train_wall": "351"}
2022-12-14 23:37:08 | INFO | fairseq.trainer | begin training epoch 6
2022-12-14 23:37:11 | INFO | train_inner | {"epoch": 6, "update": 5.057, "loss": "2.962", "nll_loss": "0.116", "accuracy": "26", "wps": "4114.7", "ups": "5.06", "wpb": "812.6", "bsz": "31.8", "num_updates": "2200", "lr": "7.16418e-07", "gnorm": "2.971", "train_wall": "13", "wall": "355"}
2022-12-14 23:37:25 | INFO | train_inner | {"epoch": 6, "update": 5.287, "loss": "2.938", "nll_loss": "0.115", "accuracy": "25.4", "wps": "5917.8", "ups": "7.24", "wpb": "817.5", "bsz": "32", "num_updates": "2300", "lr": "7.01493e-07", "gnorm": "2.898", "train_wall": "14", "wall": "369"}
2022-12-14 23:37:38 | INFO | train_inner | {"epoch": 6, "update": 5.517, "loss": "2.95", "nll_loss": "0.116", "accuracy": "25.5", "wps": "6128.3", "ups": "7.5", "wpb": "816.8", "bsz": "32", "num_updates": "2400", "lr": "6.86567e-07", "gnorm": "2.967", "train_wall": "13", "wall": "382"}
2022-12-14 23:37:53 | INFO | train_inner | {"epoch": 6, "update": 5.747, "loss": "2.931", "nll_loss": "0.115", "accuracy": "25.2", "wps": "5754", "ups": "7.05", "wpb": "816", "bsz": "32", "num_updates": "2500", "lr": "6.71642e-07", "gnorm": "2.936", "train_wall": "14", "wall": "396"}
2022-12-14 23:38:07 | INFO | train_inner | {"epoch": 6, "update": 5.977, "loss": "2.932", "nll_loss": "0.115", "accuracy": "25.6", "wps": "5783.1", "ups": "7.08", "wpb": "816.5", "bsz": "32", "num_updates": "2600", "lr": "6.56716e-07", "gnorm": "2.989", "train_wall": "14", "wall": "410"}
2022-12-14 23:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:38:10 | INFO | valid | {"epoch": 6, "valid_loss": "2.944", "valid_nll_loss": "0.116", "valid_accuracy": "22.1", "valid_wps": "17913.9", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "2610", "valid_best_accuracy": "26.1"}
2022-12-14 23:38:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2610 updates
2022-12-14 23:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 6 @ 2610 updates, score 22.1) (writing took 3.2474954542703927 seconds)
2022-12-14 23:38:13 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-12-14 23:38:14 | INFO | train | {"epoch": 6, "train_loss": "2.938", "train_nll_loss": "0.115", "train_accuracy": "25.4", "train_wps": "5406.8", "train_ups": "6.63", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "2610", "train_lr": "6.55224e-07", "train_gnorm": "2.951", "train_train_wall": "59", "train_wall": "417"}
2022-12-14 23:38:14 | INFO | fairseq.trainer | begin training epoch 7
2022-12-14 23:38:27 | INFO | train_inner | {"epoch": 7, "update": 6.207, "loss": "2.885", "nll_loss": "0.113", "accuracy": "26", "wps": "4112.1", "ups": "5.06", "wpb": "812.8", "bsz": "31.8", "num_updates": "2700", "lr": "6.41791e-07", "gnorm": "2.984", "train_wall": "13", "wall": "430"}
2022-12-14 23:38:40 | INFO | train_inner | {"epoch": 7, "update": 6.437, "loss": "2.935", "nll_loss": "0.115", "accuracy": "25.1", "wps": "5897.4", "ups": "7.22", "wpb": "816.9", "bsz": "32", "num_updates": "2800", "lr": "6.26866e-07", "gnorm": "3.107", "train_wall": "14", "wall": "444"}
2022-12-14 23:38:54 | INFO | train_inner | {"epoch": 7, "update": 6.667, "loss": "2.935", "nll_loss": "0.115", "accuracy": "24.6", "wps": "5904.7", "ups": "7.24", "wpb": "816.1", "bsz": "32", "num_updates": "2900", "lr": "6.1194e-07", "gnorm": "3.02", "train_wall": "14", "wall": "458"}
2022-12-14 23:39:08 | INFO | train_inner | {"epoch": 7, "update": 6.897, "loss": "2.915", "nll_loss": "0.114", "accuracy": "25.7", "wps": "5922.6", "ups": "7.25", "wpb": "817.3", "bsz": "32", "num_updates": "3000", "lr": "5.97015e-07", "gnorm": "2.963", "train_wall": "14", "wall": "472"}
2022-12-14 23:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:39:16 | INFO | valid | {"epoch": 7, "valid_loss": "2.932", "valid_nll_loss": "0.115", "valid_accuracy": "23.9", "valid_wps": "17950.8", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3045", "valid_best_accuracy": "26.1"}
2022-12-14 23:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 3045 updates
2022-12-14 23:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 7 @ 3045 updates, score 23.9) (writing took 2.992473489139229 seconds)
2022-12-14 23:39:19 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-12-14 23:39:20 | INFO | train | {"epoch": 7, "train_loss": "2.916", "train_nll_loss": "0.114", "train_accuracy": "25.4", "train_wps": "5464.4", "train_ups": "6.7", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3045", "train_lr": "5.90299e-07", "train_gnorm": "2.996", "train_train_wall": "59", "train_wall": "483"}
2022-12-14 23:39:20 | INFO | fairseq.trainer | begin training epoch 8
2022-12-14 23:39:27 | INFO | train_inner | {"epoch": 8, "update": 7.126, "loss": "2.88", "nll_loss": "0.113", "accuracy": "26.2", "wps": "4193.2", "ups": "5.16", "wpb": "812.6", "bsz": "31.8", "num_updates": "3100", "lr": "5.8209e-07", "gnorm": "2.987", "train_wall": "13", "wall": "491"}
2022-12-14 23:39:41 | INFO | train_inner | {"epoch": 8, "update": 7.356, "loss": "2.923", "nll_loss": "0.115", "accuracy": "26", "wps": "5945.7", "ups": "7.28", "wpb": "816.3", "bsz": "32", "num_updates": "3200", "lr": "5.67164e-07", "gnorm": "3.065", "train_wall": "14", "wall": "505"}
2022-12-14 23:39:55 | INFO | train_inner | {"epoch": 8, "update": 7.586, "loss": "2.904", "nll_loss": "0.114", "accuracy": "24.9", "wps": "5819.9", "ups": "7.12", "wpb": "817", "bsz": "32", "num_updates": "3300", "lr": "5.52239e-07", "gnorm": "2.933", "train_wall": "14", "wall": "519"}
2022-12-14 23:40:09 | INFO | train_inner | {"epoch": 8, "update": 7.816, "loss": "2.921", "nll_loss": "0.115", "accuracy": "26", "wps": "5865", "ups": "7.19", "wpb": "815.9", "bsz": "32", "num_updates": "3400", "lr": "5.37313e-07", "gnorm": "2.997", "train_wall": "14", "wall": "533"}
2022-12-14 23:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:40:22 | INFO | valid | {"epoch": 8, "valid_loss": "2.924", "valid_nll_loss": "0.115", "valid_accuracy": "26.1", "valid_wps": "17885.4", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3480", "valid_best_accuracy": "26.1"}
2022-12-14 23:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3480 updates
2022-12-14 23:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 8 @ 3480 updates, score 26.1) (writing took 8.497118975967169 seconds)
2022-12-14 23:40:31 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-12-14 23:40:32 | INFO | train | {"epoch": 8, "train_loss": "2.903", "train_nll_loss": "0.114", "train_accuracy": "26", "train_wps": "5029.3", "train_ups": "6.17", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3480", "train_lr": "5.25373e-07", "train_gnorm": "3.019", "train_train_wall": "59", "train_wall": "554"}
2022-12-14 23:40:32 | INFO | fairseq.trainer | begin training epoch 9
2022-12-14 23:40:34 | INFO | train_inner | {"epoch": 9, "update": 8.046, "loss": "2.855", "nll_loss": "0.112", "accuracy": "27.5", "wps": "3230.5", "ups": "3.97", "wpb": "812.8", "bsz": "31.8", "num_updates": "3500", "lr": "5.22388e-07", "gnorm": "3.062", "train_wall": "13", "wall": "558"}
2022-12-14 23:40:48 | INFO | train_inner | {"epoch": 9, "update": 8.276, "loss": "2.892", "nll_loss": "0.113", "accuracy": "26.1", "wps": "6075.1", "ups": "7.43", "wpb": "817.3", "bsz": "32", "num_updates": "3600", "lr": "5.07463e-07", "gnorm": "3.07", "train_wall": "13", "wall": "572"}
2022-12-14 23:41:02 | INFO | train_inner | {"epoch": 9, "update": 8.506, "loss": "2.914", "nll_loss": "0.114", "accuracy": "25.3", "wps": "5932.5", "ups": "7.26", "wpb": "816.7", "bsz": "32", "num_updates": "3700", "lr": "4.92537e-07", "gnorm": "3.029", "train_wall": "14", "wall": "585"}
2022-12-14 23:41:16 | INFO | train_inner | {"epoch": 9, "update": 8.736, "loss": "2.881", "nll_loss": "0.113", "accuracy": "26.2", "wps": "5823.8", "ups": "7.14", "wpb": "816", "bsz": "32", "num_updates": "3800", "lr": "4.77612e-07", "gnorm": "3.094", "train_wall": "14", "wall": "600"}
2022-12-14 23:41:29 | INFO | train_inner | {"epoch": 9, "update": 8.966, "loss": "2.905", "nll_loss": "0.114", "accuracy": "25.7", "wps": "6018.6", "ups": "7.37", "wpb": "817", "bsz": "32", "num_updates": "3900", "lr": "4.62687e-07", "gnorm": "2.985", "train_wall": "13", "wall": "613"}
2022-12-14 23:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:41:34 | INFO | valid | {"epoch": 9, "valid_loss": "2.917", "valid_nll_loss": "0.114", "valid_accuracy": "25.4", "valid_wps": "17928.4", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "3915", "valid_best_accuracy": "26.1"}
2022-12-14 23:41:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3915 updates
2022-12-14 23:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 9 @ 3915 updates, score 25.4) (writing took 3.35120872175321 seconds)
2022-12-14 23:41:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-12-14 23:41:38 | INFO | train | {"epoch": 9, "train_loss": "2.896", "train_nll_loss": "0.113", "train_accuracy": "25.9", "train_wps": "5430.4", "train_ups": "6.66", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "3915", "train_lr": "4.60448e-07", "train_gnorm": "3.054", "train_train_wall": "59", "train_wall": "621"}
2022-12-14 23:41:38 | INFO | fairseq.trainer | begin training epoch 10
2022-12-14 23:41:50 | INFO | train_inner | {"epoch": 10, "update": 9.195, "loss": "2.914", "nll_loss": "0.114", "accuracy": "25.5", "wps": "4007", "ups": "4.93", "wpb": "812.6", "bsz": "31.8", "num_updates": "4000", "lr": "4.47761e-07", "gnorm": "3.105", "train_wall": "14", "wall": "633"}
2022-12-14 23:42:03 | INFO | train_inner | {"epoch": 10, "update": 9.425, "loss": "2.882", "nll_loss": "0.113", "accuracy": "26.3", "wps": "6049", "ups": "7.4", "wpb": "817.3", "bsz": "32", "num_updates": "4100", "lr": "4.32836e-07", "gnorm": "3.033", "train_wall": "13", "wall": "647"}
2022-12-14 23:42:17 | INFO | train_inner | {"epoch": 10, "update": 9.655, "loss": "2.886", "nll_loss": "0.113", "accuracy": "26.6", "wps": "6003.8", "ups": "7.35", "wpb": "817.2", "bsz": "32", "num_updates": "4200", "lr": "4.1791e-07", "gnorm": "3.067", "train_wall": "13", "wall": "661"}
2022-12-14 23:42:31 | INFO | train_inner | {"epoch": 10, "update": 9.885, "loss": "2.899", "nll_loss": "0.114", "accuracy": "25.6", "wps": "5915.5", "ups": "7.25", "wpb": "816.4", "bsz": "32", "num_updates": "4300", "lr": "4.02985e-07", "gnorm": "3.101", "train_wall": "14", "wall": "674"}
2022-12-14 23:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:42:40 | INFO | valid | {"epoch": 10, "valid_loss": "2.913", "valid_nll_loss": "0.114", "valid_accuracy": "26.5", "valid_wps": "16373.5", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "4350", "valid_best_accuracy": "26.5"}
2022-12-14 23:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4350 updates
2022-12-14 23:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:42:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_best_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 10 @ 4350 updates, score 26.5) (writing took 8.476771143265069 seconds)
2022-12-14 23:42:49 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-12-14 23:42:49 | INFO | train | {"epoch": 10, "train_loss": "2.889", "train_nll_loss": "0.113", "train_accuracy": "26.1", "train_wps": "5021.4", "train_ups": "6.16", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "4350", "train_lr": "3.95522e-07", "train_gnorm": "3.065", "train_train_wall": "59", "train_wall": "692"}
2022-12-14 23:42:49 | INFO | fairseq.trainer | begin training epoch 11
2022-12-14 23:42:57 | INFO | train_inner | {"epoch": 11, "update": 10.115, "loss": "2.89", "nll_loss": "0.113", "accuracy": "26.2", "wps": "3153.9", "ups": "3.88", "wpb": "812.3", "bsz": "31.8", "num_updates": "4400", "lr": "3.8806e-07", "gnorm": "3.069", "train_wall": "14", "wall": "700"}
2022-12-14 23:43:10 | INFO | train_inner | {"epoch": 11, "update": 10.345, "loss": "2.919", "nll_loss": "0.114", "accuracy": "25.9", "wps": "5867.2", "ups": "7.18", "wpb": "816.9", "bsz": "32", "num_updates": "4500", "lr": "3.73134e-07", "gnorm": "3.011", "train_wall": "14", "wall": "714"}
2022-12-14 23:43:24 | INFO | train_inner | {"epoch": 11, "update": 10.575, "loss": "2.831", "nll_loss": "0.111", "accuracy": "27.9", "wps": "6179.3", "ups": "7.56", "wpb": "817.2", "bsz": "32", "num_updates": "4600", "lr": "3.58209e-07", "gnorm": "3.048", "train_wall": "13", "wall": "727"}
2022-12-14 23:43:37 | INFO | train_inner | {"epoch": 11, "update": 10.805, "loss": "2.891", "nll_loss": "0.113", "accuracy": "26.1", "wps": "6071.7", "ups": "7.43", "wpb": "816.8", "bsz": "32", "num_updates": "4700", "lr": "3.43284e-07", "gnorm": "3.117", "train_wall": "13", "wall": "741"}
2022-12-14 23:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:43:51 | INFO | valid | {"epoch": 11, "valid_loss": "2.909", "valid_nll_loss": "0.114", "valid_accuracy": "25.7", "valid_wps": "17896.6", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "4785", "valid_best_accuracy": "26.5"}
2022-12-14 23:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4785 updates
2022-12-14 23:43:54 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 11 @ 4785 updates, score 25.7) (writing took 2.991973645053804 seconds)
2022-12-14 23:43:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-12-14 23:43:55 | INFO | train | {"epoch": 11, "train_loss": "2.886", "train_nll_loss": "0.113", "train_accuracy": "26.4", "train_wps": "5462.5", "train_ups": "6.7", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "4785", "train_lr": "3.30597e-07", "train_gnorm": "3.117", "train_train_wall": "59", "train_wall": "758"}
2022-12-14 23:43:55 | INFO | fairseq.trainer | begin training epoch 12
2022-12-14 23:43:58 | INFO | train_inner | {"epoch": 12, "update": 11.034, "loss": "2.865", "nll_loss": "0.112", "accuracy": "26.7", "wps": "3993.3", "ups": "4.92", "wpb": "811.6", "bsz": "31.8", "num_updates": "4800", "lr": "3.28358e-07", "gnorm": "3.302", "train_wall": "14", "wall": "761"}
2022-12-14 23:44:11 | INFO | train_inner | {"epoch": 12, "update": 11.264, "loss": "2.873", "nll_loss": "0.113", "accuracy": "26.4", "wps": "5959.3", "ups": "7.3", "wpb": "816.6", "bsz": "32", "num_updates": "4900", "lr": "3.13433e-07", "gnorm": "3.159", "train_wall": "14", "wall": "775"}
2022-12-14 23:44:25 | INFO | train_inner | {"epoch": 12, "update": 11.494, "loss": "2.901", "nll_loss": "0.114", "accuracy": "26.9", "wps": "5966.9", "ups": "7.3", "wpb": "817", "bsz": "32", "num_updates": "5000", "lr": "2.98507e-07", "gnorm": "3.147", "train_wall": "14", "wall": "789"}
2022-12-14 23:44:39 | INFO | train_inner | {"epoch": 12, "update": 11.724, "loss": "2.873", "nll_loss": "0.113", "accuracy": "27.8", "wps": "5843.1", "ups": "7.16", "wpb": "816.2", "bsz": "32", "num_updates": "5100", "lr": "2.83582e-07", "gnorm": "3.182", "train_wall": "14", "wall": "803"}
2022-12-14 23:44:53 | INFO | train_inner | {"epoch": 12, "update": 11.954, "loss": "2.891", "nll_loss": "0.113", "accuracy": "26", "wps": "6063.3", "ups": "7.42", "wpb": "817.2", "bsz": "32", "num_updates": "5200", "lr": "2.68657e-07", "gnorm": "3.187", "train_wall": "13", "wall": "816"}
2022-12-14 23:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:44:57 | INFO | valid | {"epoch": 12, "valid_loss": "2.906", "valid_nll_loss": "0.114", "valid_accuracy": "25.4", "valid_wps": "17913.8", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "5220", "valid_best_accuracy": "26.5"}
2022-12-14 23:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 5220 updates
2022-12-14 23:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 12 @ 5220 updates, score 25.4) (writing took 3.0223720292560756 seconds)
2022-12-14 23:45:00 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-12-14 23:45:01 | INFO | train | {"epoch": 12, "train_loss": "2.88", "train_nll_loss": "0.113", "train_accuracy": "27.1", "train_wps": "5453.7", "train_ups": "6.69", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "5220", "train_lr": "2.65672e-07", "train_gnorm": "3.169", "train_train_wall": "59", "train_wall": "824"}
2022-12-14 23:45:01 | INFO | fairseq.trainer | begin training epoch 13
2022-12-14 23:45:12 | INFO | train_inner | {"epoch": 13, "update": 12.184, "loss": "2.903", "nll_loss": "0.114", "accuracy": "26.9", "wps": "4144.9", "ups": "5.11", "wpb": "811.9", "bsz": "31.8", "num_updates": "5300", "lr": "2.53731e-07", "gnorm": "3.224", "train_wall": "13", "wall": "836"}
2022-12-14 23:45:26 | INFO | train_inner | {"epoch": 13, "update": 12.414, "loss": "2.864", "nll_loss": "0.112", "accuracy": "28.9", "wps": "5872.3", "ups": "7.19", "wpb": "817.2", "bsz": "32", "num_updates": "5400", "lr": "2.38806e-07", "gnorm": "3.05", "train_wall": "14", "wall": "850"}
2022-12-14 23:45:40 | INFO | train_inner | {"epoch": 13, "update": 12.644, "loss": "2.834", "nll_loss": "0.111", "accuracy": "29.2", "wps": "5969.4", "ups": "7.3", "wpb": "817.9", "bsz": "32", "num_updates": "5500", "lr": "2.23881e-07", "gnorm": "3.183", "train_wall": "14", "wall": "864"}
2022-12-14 23:45:53 | INFO | train_inner | {"epoch": 13, "update": 12.874, "loss": "2.918", "nll_loss": "0.114", "accuracy": "25.9", "wps": "6076.9", "ups": "7.44", "wpb": "816.5", "bsz": "32", "num_updates": "5600", "lr": "2.08955e-07", "gnorm": "3.077", "train_wall": "13", "wall": "877"}
2022-12-14 23:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:46:03 | INFO | valid | {"epoch": 13, "valid_loss": "2.903", "valid_nll_loss": "0.114", "valid_accuracy": "24.6", "valid_wps": "17898.8", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "5655", "valid_best_accuracy": "26.5"}
2022-12-14 23:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5655 updates
2022-12-14 23:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 13 @ 5655 updates, score 24.6) (writing took 3.0243511237204075 seconds)
2022-12-14 23:46:06 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-12-14 23:46:07 | INFO | train | {"epoch": 13, "train_loss": "2.877", "train_nll_loss": "0.113", "train_accuracy": "27.6", "train_wps": "5450.7", "train_ups": "6.68", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "5655", "train_lr": "2.00746e-07", "train_gnorm": "3.126", "train_train_wall": "59", "train_wall": "890"}
2022-12-14 23:46:07 | INFO | fairseq.trainer | begin training epoch 14
2022-12-14 23:46:13 | INFO | train_inner | {"epoch": 14, "update": 13.103, "loss": "2.87", "nll_loss": "0.113", "accuracy": "27.4", "wps": "4050.4", "ups": "4.99", "wpb": "811.5", "bsz": "31.8", "num_updates": "5700", "lr": "1.9403e-07", "gnorm": "3.059", "train_wall": "14", "wall": "897"}
2022-12-14 23:46:27 | INFO | train_inner | {"epoch": 14, "update": 13.333, "loss": "2.867", "nll_loss": "0.112", "accuracy": "26.9", "wps": "5859.2", "ups": "7.17", "wpb": "817.4", "bsz": "32", "num_updates": "5800", "lr": "1.79104e-07", "gnorm": "3.188", "train_wall": "14", "wall": "911"}
2022-12-14 23:46:41 | INFO | train_inner | {"epoch": 14, "update": 13.563, "loss": "2.876", "nll_loss": "0.113", "accuracy": "28.2", "wps": "5953.2", "ups": "7.29", "wpb": "816.2", "bsz": "32", "num_updates": "5900", "lr": "1.64179e-07", "gnorm": "3.13", "train_wall": "14", "wall": "925"}
2022-12-14 23:46:55 | INFO | train_inner | {"epoch": 14, "update": 13.793, "loss": "2.853", "nll_loss": "0.112", "accuracy": "27.7", "wps": "6063.6", "ups": "7.42", "wpb": "817.5", "bsz": "32", "num_updates": "6000", "lr": "1.49254e-07", "gnorm": "3.054", "train_wall": "13", "wall": "938"}
2022-12-14 23:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:47:09 | INFO | valid | {"epoch": 14, "valid_loss": "2.901", "valid_nll_loss": "0.114", "valid_accuracy": "24.5", "valid_wps": "17924.2", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6090", "valid_best_accuracy": "26.5"}
2022-12-14 23:47:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 6090 updates
2022-12-14 23:47:12 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:47:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 14 @ 6090 updates, score 24.5) (writing took 3.027841466013342 seconds)
2022-12-14 23:47:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-12-14 23:47:13 | INFO | train | {"epoch": 14, "train_loss": "2.874", "train_nll_loss": "0.113", "train_accuracy": "27.3", "train_wps": "5438.9", "train_ups": "6.67", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6090", "train_lr": "1.35821e-07", "train_gnorm": "3.147", "train_train_wall": "59", "train_wall": "956"}
2022-12-14 23:47:13 | INFO | fairseq.trainer | begin training epoch 15
2022-12-14 23:47:15 | INFO | train_inner | {"epoch": 15, "update": 14.023, "loss": "2.897", "nll_loss": "0.114", "accuracy": "26.3", "wps": "4032.8", "ups": "4.97", "wpb": "812.2", "bsz": "31.8", "num_updates": "6100", "lr": "1.34328e-07", "gnorm": "3.26", "train_wall": "14", "wall": "959"}
2022-12-14 23:47:29 | INFO | train_inner | {"epoch": 15, "update": 14.253, "loss": "2.883", "nll_loss": "0.113", "accuracy": "27.8", "wps": "5932.3", "ups": "7.26", "wpb": "817", "bsz": "32", "num_updates": "6200", "lr": "1.19403e-07", "gnorm": "3.027", "train_wall": "14", "wall": "972"}
2022-12-14 23:47:43 | INFO | train_inner | {"epoch": 15, "update": 14.483, "loss": "2.87", "nll_loss": "0.113", "accuracy": "27.8", "wps": "5900.1", "ups": "7.23", "wpb": "816", "bsz": "32", "num_updates": "6300", "lr": "1.04478e-07", "gnorm": "3.212", "train_wall": "14", "wall": "986"}
2022-12-14 23:47:56 | INFO | train_inner | {"epoch": 15, "update": 14.713, "loss": "2.862", "nll_loss": "0.112", "accuracy": "28", "wps": "5945.5", "ups": "7.27", "wpb": "817.5", "bsz": "32", "num_updates": "6400", "lr": "8.95522e-08", "gnorm": "3.105", "train_wall": "14", "wall": "1000"}
2022-12-14 23:48:10 | INFO | train_inner | {"epoch": 15, "update": 14.943, "loss": "2.862", "nll_loss": "0.112", "accuracy": "27.7", "wps": "5973.1", "ups": "7.32", "wpb": "816.1", "bsz": "32", "num_updates": "6500", "lr": "7.46269e-08", "gnorm": "3.166", "train_wall": "14", "wall": "1014"}
2022-12-14 23:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:48:16 | INFO | valid | {"epoch": 15, "valid_loss": "2.899", "valid_nll_loss": "0.114", "valid_accuracy": "24.6", "valid_wps": "17920.4", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6525", "valid_best_accuracy": "26.5"}
2022-12-14 23:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6525 updates
2022-12-14 23:48:19 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:48:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 15 @ 6525 updates, score 24.6) (writing took 2.96803559968248 seconds)
2022-12-14 23:48:19 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-12-14 23:48:20 | INFO | train | {"epoch": 15, "train_loss": "2.872", "train_nll_loss": "0.113", "train_accuracy": "27.7", "train_wps": "5430.1", "train_ups": "6.66", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6525", "train_lr": "7.08955e-08", "train_gnorm": "3.131", "train_train_wall": "59", "train_wall": "1022"}
2022-12-14 23:48:20 | INFO | fairseq.trainer | begin training epoch 16
2022-12-14 23:48:30 | INFO | train_inner | {"epoch": 16, "update": 15.172, "loss": "2.876", "nll_loss": "0.113", "accuracy": "27.6", "wps": "4090.4", "ups": "5.03", "wpb": "812.6", "bsz": "31.8", "num_updates": "6600", "lr": "5.97015e-08", "gnorm": "3.171", "train_wall": "14", "wall": "1034"}
2022-12-14 23:48:44 | INFO | train_inner | {"epoch": 16, "update": 15.402, "loss": "2.871", "nll_loss": "0.113", "accuracy": "27.3", "wps": "5949.2", "ups": "7.29", "wpb": "816.4", "bsz": "32", "num_updates": "6700", "lr": "4.47761e-08", "gnorm": "3.148", "train_wall": "14", "wall": "1047"}
2022-12-14 23:48:57 | INFO | train_inner | {"epoch": 16, "update": 15.632, "loss": "2.867", "nll_loss": "0.112", "accuracy": "28.8", "wps": "5916.7", "ups": "7.24", "wpb": "816.8", "bsz": "32", "num_updates": "6800", "lr": "2.98507e-08", "gnorm": "3.258", "train_wall": "14", "wall": "1061"}
2022-12-14 23:49:11 | INFO | train_inner | {"epoch": 16, "update": 15.862, "loss": "2.85", "nll_loss": "0.112", "accuracy": "29.2", "wps": "5889.7", "ups": "7.21", "wpb": "817", "bsz": "32", "num_updates": "6900", "lr": "1.49254e-08", "gnorm": "3.256", "train_wall": "14", "wall": "1075"}
2022-12-14 23:49:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:49:22 | INFO | valid | {"epoch": 16, "valid_loss": "2.899", "valid_nll_loss": "0.114", "valid_accuracy": "24.6", "valid_wps": "17883.9", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "6960", "valid_best_accuracy": "26.5"}
2022-12-14 23:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6960 updates
2022-12-14 23:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:49:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 16 @ 6960 updates, score 24.6) (writing took 3.0170822837390006 seconds)
2022-12-14 23:49:25 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-12-14 23:49:26 | INFO | train | {"epoch": 16, "train_loss": "2.871", "train_nll_loss": "0.112", "train_accuracy": "27.9", "train_wps": "5437", "train_ups": "6.66", "train_wpb": "815.8", "train_bsz": "32", "train_num_updates": "6960", "train_lr": "5.97015e-09", "train_gnorm": "3.224", "train_train_wall": "59", "train_wall": "1089"}
2022-12-14 23:49:26 | INFO | fairseq.trainer | begin training epoch 17
2022-12-14 23:49:31 | INFO | train_inner | {"epoch": 17, "update": 16.092, "loss": "2.913", "nll_loss": "0.114", "accuracy": "25.7", "wps": "4093.6", "ups": "5.03", "wpb": "813.1", "bsz": "31.8", "num_updates": "7000", "lr": "0", "gnorm": "3.238", "train_wall": "14", "wall": "1095"}
2022-12-14 23:49:31 | INFO | fairseq_cli.train | Stopping training due to num_updates: 7000 >= max_update: 7000
2022-12-14 23:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-12-14 23:49:34 | INFO | valid | {"epoch": 17, "valid_loss": "2.899", "valid_nll_loss": "0.114", "valid_accuracy": "24.6", "valid_wps": "17804.7", "valid_wpb": "101.7", "valid_bsz": "4", "valid_num_updates": "7000", "valid_best_accuracy": "26.5"}
2022-12-14 23:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 7000 updates
2022-12-14 23:49:37 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt
2022-12-14 23:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_last_xai_apex_M2P_1e-6_small_tmp.pt.pt (epoch 17 @ 7000 updates, score 24.6) (writing took 2.996593303978443 seconds)
2022-12-14 23:49:37 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-12-14 23:49:37 | INFO | train | {"epoch": 17, "train_loss": "2.89", "train_nll_loss": "0.113", "train_accuracy": "26.8", "train_wps": "3022.6", "train_ups": "3.7", "train_wpb": "817.2", "train_bsz": "32", "train_num_updates": "7000", "train_lr": "0", "train_gnorm": "3.115", "train_train_wall": "5", "train_wall": "1100"}
2022-12-14 23:49:37 | INFO | fairseq_cli.train | done training in 1100.9 seconds
